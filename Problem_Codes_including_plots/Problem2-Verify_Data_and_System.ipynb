{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5719dacf",
   "metadata": {},
   "source": [
    "## Helper: Building a Weekly Panel with True Eliminations and Fan Shares\n",
    "\n",
    "This helper module takes the original wide-format DWTS data and the estimated fan shares, and converts them into a **clean weekly panel** that can be used for downstream analyses (consistency checks, certainty, voting-rule simulations, etc.).\n",
    "\n",
    "### 1. Parsing Elimination Week\n",
    "\n",
    "We first parse the `results` field from the COMAP CSV to extract each contestant’s *elimination week*:\n",
    "\n",
    "- Strings like `\"Eliminated Week 3\"` are mapped to `elim_week = 3`.\n",
    "- Winners, finalists, or runners-up (e.g., `\"1st Place\"`, `\"2nd Place\"`) are treated as **never eliminated**, and assigned `elim_week = ∞`.\n",
    "\n",
    "This gives a numeric indicator we can compare to week numbers.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Constructing the Weekly Panel\n",
    "\n",
    "The core function:\n",
    "\n",
    "```python\n",
    "build_weekly_panel(df_raw, fan_df) -> df_panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60ffb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 1. Parse elimination week from \"results\" field\n",
    "#    e.g. \"Eliminated Week 3\" -> 3\n",
    "#         \"1st Place\"          -> np.inf (never eliminated)\n",
    "# ============================================================\n",
    "\n",
    "def parse_elim_week(result_str: str):\n",
    "    if pd.isna(result_str):\n",
    "        return np.inf\n",
    "    result_str = str(result_str)\n",
    "    # Typical pattern: \"Eliminated Week X\"\n",
    "    if \"Eliminated Week\" in result_str:\n",
    "        # extract last token and cast to int if possible\n",
    "        last = result_str.split()[-1]\n",
    "        try:\n",
    "            return int(last)\n",
    "        except ValueError:\n",
    "            return np.inf\n",
    "    # Winners / runners-up etc: treat as never eliminated\n",
    "    return np.inf\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Build a \"weekly panel\" dataframe:\n",
    "#    one row per (season, week, celebrity_name)\n",
    "#    with judge totals, fan shares, and real elimination flag\n",
    "# ============================================================\n",
    "\n",
    "def build_weekly_panel(df_raw: pd.DataFrame,\n",
    "                       fan_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ------\n",
    "    df_raw : wide-format DWTS dataset from COMAP CSV.\n",
    "             Must have columns:\n",
    "               - 'season'\n",
    "               - 'celebrity_name'\n",
    "               - 'results'\n",
    "               - weekX_judgeY_score columns.\n",
    "\n",
    "    fan_df : long-format table with columns:\n",
    "               - 'season'\n",
    "               - 'week'\n",
    "               - 'celebrity_name'\n",
    "               - 'F_hat'  (estimated fan vote share, sums to 1 within season-week)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_panel : long-format dataframe with columns:\n",
    "        ['season', 'week', 'celebrity_name',\n",
    "         'judge_total', 'F_hat',\n",
    "         'is_active', 'eliminated_real']\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_raw.copy()\n",
    "\n",
    "    # ---------- 2.1 compute each contestant's elimination week ----------\n",
    "    df[\"elim_week\"] = df[\"results\"].apply(parse_elim_week)\n",
    "\n",
    "    # ---------- 2.2 identify judge score columns & max week ----------\n",
    "    judge_cols = [c for c in df.columns\n",
    "                  if c.startswith(\"week\") and c.endswith(\"_total_score\")]\n",
    "    if not judge_cols:\n",
    "        # If you only have individual judge scores, sum them first.\n",
    "        # Example: week1_judge1_score, week1_judge2_score, ...\n",
    "        # We build weekX_total_score on the fly.\n",
    "        week_tags = sorted(\n",
    "            set(col.split(\"_judge\")[0] for col in df.columns\n",
    "                if col.startswith(\"week\") and \"_judge\" in col and col.endswith(\"_score\"))\n",
    "        )\n",
    "        for wtag in week_tags:\n",
    "            sub = [c for c in df.columns if c.startswith(wtag) and c.endswith(\"_score\")]\n",
    "            df[f\"{wtag}_total_score\"] = df[sub].sum(axis=1)\n",
    "        judge_cols = [c for c in df.columns\n",
    "                      if c.startswith(\"week\") and c.endswith(\"_total_score\")]\n",
    "\n",
    "    # Map week number from column name \"weekX_total_score\"\n",
    "    week_nums = sorted(int(col[4:].split(\"_\")[0]) for col in judge_cols)\n",
    "    max_week = max(week_nums)\n",
    "\n",
    "    # ---------- 2.3 wide -> long for judge totals ----------\n",
    "    judge_long = []\n",
    "    for week in week_nums:\n",
    "        col = f\"week{week}_total_score\"\n",
    "        tmp = df[[\"season\", \"celebrity_name\", \"elim_week\", \"results\", col]].copy()\n",
    "        tmp = tmp.rename(columns={col: \"judge_total\"})\n",
    "        tmp[\"week\"] = week\n",
    "        judge_long.append(tmp)\n",
    "\n",
    "    df_j = pd.concat(judge_long, ignore_index=True)\n",
    "\n",
    "    # ---------- 2.4 active flag: contestant is active if week <= elim_week ----------\n",
    "    df_j[\"is_active\"] = df_j[\"week\"] <= df_j[\"elim_week\"]\n",
    "\n",
    "    # For contestants that were never eliminated (elim_week = inf),\n",
    "    # we still only care about weeks where the show actually ran.\n",
    "    # You can optionally filter by non-NA judge_total:\n",
    "    df_j[\"is_active\"] &= df_j[\"judge_total\"].notna()\n",
    "\n",
    "    # ---------- 2.5 real elimination: True if this is the week they were eliminated ----------\n",
    "    # Note: winners have elim_week = inf, so never flagged as eliminated_real.\n",
    "    df_j[\"eliminated_real\"] = (df_j[\"week\"] == df_j[\"elim_week\"])\n",
    "\n",
    "    # ---------- 2.6 merge fan estimates ----------\n",
    "    # fan_df must be unique per (season, week, celebrity_name)\n",
    "    df_fan = fan_df.copy()\n",
    "    df_fan = df_fan.rename(columns={\"fan_share\": \"F_hat\"}) if \"fan_share\" in df_fan.columns else df_fan\n",
    "\n",
    "    df_panel = df_j.merge(df_fan,\n",
    "                          on=[\"season\", \"week\", \"celebrity_name\"],\n",
    "                          how=\"left\")\n",
    "\n",
    "    return df_panel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea09f3",
   "metadata": {},
   "source": [
    "## Comparing Rank-Sum and Percent-Sum Elimination Rules\n",
    "\n",
    "This function directly compares the two elimination rules used on *Dancing with the Stars*—**Rank-Sum** and **Percent-Sum**—using the same reconstructed fan vote shares.\n",
    "\n",
    "### Input\n",
    "\n",
    "`df_panel` is a long-format weekly panel with one row per `(season, week, contestant)`, containing:\n",
    "\n",
    "- `season`, `week`\n",
    "- `celebrity_name`\n",
    "- `judge_total` — total judges’ score that week\n",
    "- `fan_share_hat` — estimated fan vote share from the fan model\n",
    "- `eliminated` — indicator for the actual elimination (1 if eliminated that week)\n",
    "\n",
    "Only contestants with valid judge scores and fan shares are used in each week.\n",
    "\n",
    "---\n",
    "\n",
    "### Elimination Rules Implemented\n",
    "\n",
    "For each week’s active contestant set \\( C_t \\):\n",
    "\n",
    "1. **Rank-Sum rule**\n",
    "   - Rank contestants by judges’ score and by fan share separately (1 = best).\n",
    "   - Compute the combined rank\n",
    "     \\[\n",
    "     S^{\\text{rank}}_{it} = \\text{rank}_J(i,t) + \\text{rank}_F(i,t).\n",
    "     \\]\n",
    "   - Predict the eliminated contestant as the one with the **largest** combined rank.\n",
    "\n",
    "2. **Percent-Sum rule**\n",
    "   - Convert judges’ totals to weekly percentages.\n",
    "   - Normalize fan shares within the same week.\n",
    "   - Compute the combined percentage\n",
    "     \\[\n",
    "     S^{\\text{pct}}_{it} = J^{\\%}_{it} + F^{\\%}_{it}.\n",
    "     \\]\n",
    "   - Predict the eliminated contestant as the one with the **smallest** combined percentage.\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs and Diagnostics\n",
    "\n",
    "For each `(season, week)`, the function returns:\n",
    "\n",
    "- `eliminated_rank` — contestant eliminated under the Rank-Sum rule\n",
    "- `eliminated_pct` — contestant eliminated under the Percent-Sum rule\n",
    "- `eliminated_real` — actual eliminated contestant (only defined when exactly one elimination occurred)\n",
    "- `disagree` — whether the two rules eliminate different contestants\n",
    "- `delta_F_rank_minus_pct` — difference in fan share between the Rank-Sum loser and Percent-Sum loser (only when they disagree)\n",
    "- `delta_J_rank_minus_pct` — difference in judges’ score between the two losers (only when they disagree)\n",
    "- `n_contestants` — number of active contestants that week\n",
    "- `n_real_elims` — number of actual eliminations that week\n",
    "\n",
    "This comparison isolates **when and why** the two rules diverge, and quantifies whether disagreements are primarily driven by differences in **fan support** or **judges’ evaluations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357ea70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def simulate_rank_vs_pct(df_panel: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    df_panel: long-format dataframe with at least:\n",
    "        - 'season'\n",
    "        - 'week'\n",
    "        - 'celebrity_name'\n",
    "        - 'judge_total'\n",
    "        - 'fan_share_hat'   (estimated fan share from your model)\n",
    "        - 'eliminated'      (1 if actually eliminated this week, else 0)\n",
    "\n",
    "    Returns:\n",
    "        week_results: one row per (season, week) with\n",
    "          - eliminated_rank: elimination under rank rule\n",
    "          - eliminated_pct:  elimination under percent rule\n",
    "          - eliminated_real: actual elimination (if exactly one)\n",
    "          - disagree:        True if rank vs pct give different loser\n",
    "          - delta_F_rank_minus_pct: fan_share_rank - fan_share_pct (when disagree)\n",
    "          - delta_J_rank_minus_pct: judge_rank - judge_pct (when disagree)\n",
    "          - n_contestants, n_real_elims\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # group by season & week (this is your A_t set)\n",
    "    for (season, week), sub in df_panel.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Safety: drop rows lacking key info\n",
    "        sub = sub.dropna(subset=[\"judge_total\", \"fan_share_hat\"])\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # --- normalize fan shares within this week (just in case) ---\n",
    "        total_fan = sub[\"fan_share_hat\"].sum()\n",
    "        if total_fan <= 0 or np.isnan(total_fan):\n",
    "            # if your model somehow produced zero mass this week, skip it\n",
    "            continue\n",
    "        sub[\"F_norm\"] = sub[\"fan_share_hat\"] / total_fan\n",
    "\n",
    "        # ======================= RANK METHOD =======================\n",
    "        # Higher judge_total => better (rank 1)\n",
    "        sub[\"r_judge\"] = sub[\"judge_total\"].rank(\n",
    "            ascending=False, method=\"min\"\n",
    "        )\n",
    "        # Higher fan share => better (rank 1)\n",
    "        sub[\"r_fan\"] = sub[\"F_norm\"].rank(\n",
    "            ascending=False, method=\"min\"\n",
    "        )\n",
    "        sub[\"S_rank\"] = sub[\"r_judge\"] + sub[\"r_fan\"]\n",
    "\n",
    "        # Worst = largest sum of ranks (ties broken by first appearance)\n",
    "        worst_rank_idx = sub[\"S_rank\"].idxmax()\n",
    "        elim_rank = sub.loc[worst_rank_idx, \"celebrity_name\"]\n",
    "\n",
    "        # ===================== PERCENT METHOD ======================\n",
    "        judge_sum = sub[\"judge_total\"].sum()\n",
    "        sub[\"P_judge\"] = sub[\"judge_total\"] / judge_sum        # judge %\n",
    "        sub[\"P_fan\"]   = sub[\"F_norm\"]                         # fan %, already normalized\n",
    "        sub[\"S_pct\"]   = sub[\"P_judge\"] + sub[\"P_fan\"]\n",
    "\n",
    "        # Worst = smallest combined percent\n",
    "        worst_pct_idx = sub[\"S_pct\"].idxmin()\n",
    "        elim_pct = sub.loc[worst_pct_idx, \"celebrity_name\"]\n",
    "\n",
    "        # ====================== REAL ELIMINATION ==================\n",
    "        # Some weeks have 0 or >1 eliminations. For “match” stats we only\n",
    "        # use weeks with exactly 1 eliminated contestant.\n",
    "        eliminated_rows = sub[sub.get(\"eliminated\", 0) == 1]\n",
    "        real_elims = eliminated_rows[\"celebrity_name\"].tolist()\n",
    "        real_elim = real_elims[0] if len(real_elims) == 1 else None\n",
    "\n",
    "        # ====================== DISAGREEMENT =======================\n",
    "        disagree = (elim_rank != elim_pct)\n",
    "\n",
    "        delta_F = np.nan\n",
    "        delta_J = np.nan\n",
    "        if disagree:\n",
    "            # fan share of contestant eliminated by rank vs pct\n",
    "            F_rank = sub.loc[sub[\"celebrity_name\"] == elim_rank, \"F_norm\"].iloc[0]\n",
    "            F_pct  = sub.loc[sub[\"celebrity_name\"] == elim_pct,  \"F_norm\"].iloc[0]\n",
    "            delta_F = F_rank - F_pct\n",
    "\n",
    "            # judge total of contestant eliminated by rank vs pct\n",
    "            J_rank = sub.loc[sub[\"celebrity_name\"] == elim_rank, \"judge_total\"].iloc[0]\n",
    "            J_pct  = sub.loc[sub[\"celebrity_name\"] == elim_pct,  \"judge_total\"].iloc[0]\n",
    "            delta_J = J_rank - J_pct\n",
    "\n",
    "        rows.append({\n",
    "            \"season\": season,\n",
    "            \"week\": week,\n",
    "            \"eliminated_rank\": elim_rank,\n",
    "            \"eliminated_pct\": elim_pct,\n",
    "            \"eliminated_real\": real_elim,\n",
    "            \"disagree\": disagree,\n",
    "            \"delta_F_rank_minus_pct\": delta_F,\n",
    "            \"delta_J_rank_minus_pct\": delta_J,\n",
    "            \"n_contestants\": len(sub),\n",
    "            \"n_real_elims\": len(real_elims),\n",
    "        })\n",
    "\n",
    "    week_results = pd.DataFrame(rows)\n",
    "    return week_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e247d",
   "metadata": {},
   "source": [
    "## Summary of Rank vs. Percent Comparison Results\n",
    "\n",
    "This helper function takes the week-level comparison between the **Rank-Sum** and **Percent-Sum** rules and computes a set of global and per-season statistics for the writeup.\n",
    "\n",
    "### Input\n",
    "\n",
    "`week_results`: a DataFrame produced by `simulate_rank_vs_pct`, with one row per `(season, week)` containing at least:\n",
    "\n",
    "- `season`, `week`\n",
    "- `disagree` — whether Rank-Sum and Percent-Sum eliminate different contestants\n",
    "- `delta_F_rank_minus_pct` — fan-share difference between the Rank loser and Percent loser\n",
    "- `delta_J_rank_minus_pct` — judge-score difference between the Rank loser and Percent loser\n",
    "- `eliminated_rank`, `eliminated_pct` — losers under each rule\n",
    "- `eliminated_real` — actual eliminated contestant (only defined when there is exactly one elimination)\n",
    "\n",
    "---\n",
    "\n",
    "### Global Summary Metrics\n",
    "\n",
    "The function first computes **aggregate statistics** across all weeks:\n",
    "\n",
    "- `total_weeks`  \n",
    "  Total number of (season, week) instances considered.\n",
    "\n",
    "- `disagree_weeks`  \n",
    "  Number of weeks where the Rank-Sum and Percent-Sum rules eliminate **different** contestants.\n",
    "\n",
    "- `disagreement_rate`  \n",
    "  Fraction of weeks with disagreement:\n",
    "  \\[\n",
    "  \\text{disagreement\\_rate} = \\frac{\\text{disagree\\_weeks}}{\\text{total\\_weeks}}.\n",
    "  \\]\n",
    "\n",
    "- `avg_delta_F_rank_minus_pct`  \n",
    "  Among weeks where the rules disagree, the average difference in fan share between the Rank-Sum loser and the Percent-Sum loser.  \n",
    "  Positive values suggest the Rank-Sum rule tends to eliminate **more popular** contestants (higher fan share) than the Percent-Sum rule.\n",
    "\n",
    "- `avg_delta_J_rank_minus_pct`  \n",
    "  Among disagreement weeks, the average difference in judge scores between the Rank-Sum loser and Percent-Sum loser.  \n",
    "  Positive values suggest Rank-Sum tends to eliminate contestants with **higher judge scores** than the Percent-Sum rule.\n",
    "\n",
    "- `rank_match_real_rate`  \n",
    "  Among weeks with exactly one actual elimination, the fraction of weeks in which the Rank-Sum loser matches the **actual** eliminated contestant.\n",
    "\n",
    "- `pct_match_real_rate`  \n",
    "  Similarly, the fraction of weeks where the Percent-Sum loser matches the actual eliminated contestant.\n",
    "\n",
    "These global metrics are returned in a dictionary `summary_global`.\n",
    "\n",
    "---\n",
    "\n",
    "### Per-Season Breakdown\n",
    "\n",
    "The function also produces a **per-season** summary table `per_season` with columns:\n",
    "\n",
    "- `season`\n",
    "- `weeks` — number of weeks observed for that season\n",
    "- `disagree_weeks` — how many weeks the two rules disagreed\n",
    "- `disagreement_rate` — fraction of weeks with disagreement in that season\n",
    "- `avg_delta_F` — within-season average of `delta_F_rank_minus_pct`\n",
    "- `avg_delta_J` — within-season average of `delta_J_rank_minus_pct`\n",
    "\n",
    "This table is useful for an appendix or figure, showing in which seasons the choice of rule mattered most, and whether those disagreements systematically favor judges or fans.\n",
    "\n",
    "---\n",
    "\n",
    "### Return Values\n",
    "\n",
    "The function returns:\n",
    "\n",
    "```python\n",
    "summary_global, per_season\n",
    "```\n",
    "- `summary_global`: a dictionary of headline numbers for the main text.\n",
    "- `per_season`: a DataFrame suitable for tables/plots in the appendix or supporting analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148c5ba",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_week_results(week_results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute the key numbers you need for the writeup:\n",
    "      - overall disagreement rate\n",
    "      - average fan-share difference when methods disagree\n",
    "      - which method matches actual show eliminations more often\n",
    "      - per-season breakdown\n",
    "    \"\"\"\n",
    "\n",
    "    total_weeks = len(week_results)\n",
    "    disagree_weeks = week_results[\"disagree\"].sum()\n",
    "    disagreement_rate = disagree_weeks / total_weeks\n",
    "\n",
    "    # Only weeks where methods disagree\n",
    "    mask_dis = week_results[\"disagree\"]\n",
    "    avg_delta_F = week_results.loc[mask_dis, \"delta_F_rank_minus_pct\"].mean()\n",
    "    avg_delta_J = week_results.loc[mask_dis, \"delta_J_rank_minus_pct\"].mean()\n",
    "\n",
    "    # Only weeks with exactly ONE real elimination\n",
    "    mask_real = week_results[\"eliminated_real\"].notna()\n",
    "    rank_match = (\n",
    "        week_results.loc[mask_real, \"eliminated_rank\"]\n",
    "        == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "    ).mean()\n",
    "    pct_match = (\n",
    "        week_results.loc[mask_real, \"eliminated_pct\"]\n",
    "        == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "    ).mean()\n",
    "\n",
    "    summary_global = {\n",
    "        \"total_weeks\": int(total_weeks),\n",
    "        \"disagree_weeks\": int(disagree_weeks),\n",
    "        \"disagreement_rate\": disagreement_rate,\n",
    "        \"avg_delta_F_rank_minus_pct\": avg_delta_F,\n",
    "        \"avg_delta_J_rank_minus_pct\": avg_delta_J,\n",
    "        \"rank_match_real_rate\": rank_match,\n",
    "        \"pct_match_real_rate\": pct_match,\n",
    "    }\n",
    "\n",
    "    # Per-season breakdown (nice table for appendix)\n",
    "    per_season = (\n",
    "        week_results\n",
    "        .groupby(\"season\")\n",
    "        .agg(\n",
    "            weeks=(\"week\", \"count\"),\n",
    "            disagree_weeks=(\"disagree\", \"sum\"),\n",
    "            disagreement_rate=(\"disagree\", \"mean\"),\n",
    "            avg_delta_F=(\"delta_F_rank_minus_pct\", \"mean\"),\n",
    "            avg_delta_J=(\"delta_J_rank_minus_pct\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return summary_global, per_season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40805014",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MAIN PIPELINE (adjust paths / fan_df construction as needed)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "df_fan = pd.read_csv(\"fan_shares_estimated.csv\")  # your model output\n",
    "\n",
    "week_results = simulate_rank_vs_pct(df_fan)\n",
    "\n",
    "summary_global, per_season = summarize_week_results(week_results)\n",
    "\n",
    "print(\"Global summary:\")\n",
    "for k, v in summary_global.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nPer-season disagreement summary (head):\")\n",
    "print(per_season.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027a47a",
   "metadata": {},
   "source": [
    "## Question 2 Analysis: Rank vs. Percent Voting Systems\n",
    "\n",
    "This module implements the full analysis pipeline for **Question 2 (Part 1)** of the MCM problem, focusing on how different methods of combining judges’ scores and fan votes affect weekly elimination outcomes.\n",
    "\n",
    "It assumes that fan vote shares have already been reconstructed in **Question 1** and saved as `fan_shares_estimated.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Weekly Simulation of Voting Rules\n",
    "\n",
    "For each season and week, the function `simulate_rank_vs_pct` applies **both** voting rules to the same set of active contestants:\n",
    "\n",
    "- **Rank-Sum rule**  \n",
    "  Contestants are ranked separately by judges’ total score and by fan vote share (1 = best).  \n",
    "  The ranks are summed, and the contestant with the **largest** combined rank is eliminated.\n",
    "\n",
    "- **Percent-Sum rule**  \n",
    "  Judges’ scores are converted into weekly percentages and added to normalized fan vote shares.  \n",
    "  The contestant with the **smallest** combined percentage is eliminated.\n",
    "\n",
    "For every `(season, week)`, the function records:\n",
    "- the predicted elimination under each rule,\n",
    "- the actual elimination (if exactly one occurred),\n",
    "- whether the two rules disagree,\n",
    "- and the fan-score and judge-score differences driving the disagreement.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Global and Per-Season Summaries\n",
    "\n",
    "The function `summarize_week_results` aggregates the week-level results into interpretable statistics:\n",
    "\n",
    "- **Disagreement rate**: how often Rank-Sum and Percent-Sum eliminate different contestants.\n",
    "- **Average fan-share difference** and **judge-score difference** when the rules disagree.\n",
    "- **Match rates**: how often each rule agrees with the actual show elimination (when uniquely defined).\n",
    "- **Per-season breakdowns** showing which seasons exhibit the strongest rule conflicts.\n",
    "\n",
    "These summaries provide quantitative evidence for comparing the two voting systems across the full history of the show.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Per-Season Accuracy Analysis\n",
    "\n",
    "`compute_per_season_accuracy` measures, for each season:\n",
    "- the accuracy of Rank-Sum,\n",
    "- the accuracy of Percent-Sum,\n",
    "- and the number of weeks with a well-defined real elimination.\n",
    "\n",
    "This allows direct season-by-season comparison of how closely each method aligns with historical outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. “Zombie” Contestant Identification\n",
    "\n",
    "The function `compute_zombies` identifies **“zombie” contestants**:\n",
    "> contestants who would be eliminated under the Percent-Sum rule (or tied for worst),  \n",
    "> but who **survive** in the actual show.\n",
    "\n",
    "These cases highlight systematic tension between fan-driven outcomes and judge-driven outcomes, and are especially relevant for controversial seasons.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Visualization Utilities\n",
    "\n",
    "The plotting functions generate publication-ready figures:\n",
    "\n",
    "- **Per-season accuracy curves** for Rank-Sum and Percent-Sum (with optional smoothing).\n",
    "- **Accuracy gap plots** showing Percent − Rank performance by season.\n",
    "- **Combined UMN-style figure**:\n",
    "  - Top: Rank vs. Percent accuracy over seasons.\n",
    "  - Bottom: Accuracy difference with highlighted zombie seasons and notable cases (e.g., Season 27).\n",
    "\n",
    "These visualizations support clear interpretation and comparison in the final report.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Script Entry Point\n",
    "\n",
    "Running the script end-to-end:\n",
    "\n",
    "1. Loads `fan_shares_estimated.csv`.\n",
    "2. Simulates Rank-Sum vs. Percent-Sum eliminations.\n",
    "3. Prints global and per-season summaries.\n",
    "4. Identifies zombie contestants (including known controversial figures).\n",
    "5. Produces a combined comparison plot saved to disk.\n",
    "\n",
    "Together, this module provides a complete, data-driven comparison of the two voting systems and directly addresses the core questions posed in **MCM Problem C – Question 2**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6248605",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analysis utilities for 2026 MCM Problem C Question 2 (Part 1).\n",
    "\n",
    "This module assumes you have already run your Question 1 fan model and\n",
    "saved its output as `fan_shares_estimated.csv`, with at least:\n",
    "\n",
    "Columns (per row = contestant-season-week):\n",
    "    - season           (int)\n",
    "    - week             (int)\n",
    "    - celebrity_name   (str)\n",
    "    - judge_total      (float)  # total judge score for that week\n",
    "    - fan_share_hat    (float)  # estimated fan share for that week\n",
    "    - eliminated       (0/1)    # 1 if actually eliminated in this week, else 0\n",
    "\n",
    "Core features:\n",
    "    - Simulate rank-based vs percent-based elimination rules.\n",
    "    - Compute disagreement rate and fan/judge differences.\n",
    "    - Compute how often each method matches real eliminations.\n",
    "    - Identify “zombie” contestants (should die under Percent, but survive).\n",
    "    - Plot per-season accuracies and Percent–Rank accuracy gap.\n",
    "\n",
    "Usage (as a script):\n",
    "    python analysis_q2.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Optional smoothing if SciPy is available\n",
    "    from scipy.interpolate import make_interp_spline\n",
    "    HAVE_SCIPY = True\n",
    "except ImportError:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Core simulation: Rank vs Percent methods\n",
    "# ============================================================\n",
    "\n",
    "def simulate_rank_vs_pct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate rank-based and percent-based elimination rules week by week.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Long-format table with columns:\n",
    "          - 'season'\n",
    "          - 'week'\n",
    "          - 'celebrity_name'\n",
    "          - 'judge_total'\n",
    "          - 'fan_share_hat'\n",
    "          - 'eliminated' (0/1)\n",
    "\n",
    "        Assumed: each row is a (season, week, contestant) where the contestant\n",
    "        is still in the competition. (No post-elimination zero rows.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    week_results : DataFrame\n",
    "        One row per (season, week) with:\n",
    "          - 'season', 'week'\n",
    "          - 'eliminated_rank'  : predicted loser under rank rule\n",
    "          - 'eliminated_pct'   : predicted loser under percent rule\n",
    "          - 'eliminated_real'  : actual loser (if exactly 1), else None\n",
    "          - 'disagree'         : True if rank vs percent differ\n",
    "          - 'delta_F_rank_minus_pct'\n",
    "          - 'delta_J_rank_minus_pct'\n",
    "          - 'n_contestants'\n",
    "          - 'n_real_elims'\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # group by season-week = A_t\n",
    "    for (season, week), sub in df.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # basic sanity: need both judge and fan info\n",
    "        sub = sub.dropna(subset=[\"judge_total\", \"fan_share_hat\"])\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # normalize fan shares within week (just in case)\n",
    "        total_fan = sub[\"fan_share_hat\"].sum()\n",
    "        if total_fan <= 0 or np.isnan(total_fan):\n",
    "            continue\n",
    "        sub[\"F_norm\"] = sub[\"fan_share_hat\"] / total_fan\n",
    "\n",
    "        # -------- Rank method --------\n",
    "        # higher judge_total => better (rank 1)\n",
    "        sub[\"r_judge\"] = sub[\"judge_total\"].rank(ascending=False, method=\"min\")\n",
    "        # higher fan share => better (rank 1)\n",
    "        sub[\"r_fan\"] = sub[\"F_norm\"].rank(ascending=False, method=\"min\")\n",
    "        sub[\"S_rank\"] = sub[\"r_judge\"] + sub[\"r_fan\"]\n",
    "\n",
    "        worst_rank_idx = sub[\"S_rank\"].idxmax()\n",
    "        elim_rank = sub.loc[worst_rank_idx, \"celebrity_name\"]\n",
    "\n",
    "        # -------- Percent method --------\n",
    "        judge_sum = sub[\"judge_total\"].sum()\n",
    "        if judge_sum <= 0:\n",
    "            # If something degenerate happens, skip this week\n",
    "            continue\n",
    "\n",
    "        sub[\"P_judge\"] = sub[\"judge_total\"] / judge_sum\n",
    "        sub[\"P_fan\"] = sub[\"F_norm\"]\n",
    "        sub[\"S_pct\"] = sub[\"P_judge\"] + sub[\"P_fan\"]\n",
    "\n",
    "        worst_pct_idx = sub[\"S_pct\"].idxmin()\n",
    "        elim_pct = sub.loc[worst_pct_idx, \"celebrity_name\"]\n",
    "\n",
    "        # -------- Real elimination --------\n",
    "        eliminated_rows = sub[sub.get(\"eliminated\", 0) == 1]\n",
    "        real_elims = eliminated_rows[\"celebrity_name\"].tolist()\n",
    "        eliminated_real = real_elims[0] if len(real_elims) == 1 else None\n",
    "\n",
    "        # -------- Disagreement analysis --------\n",
    "        disagree = (elim_rank != elim_pct)\n",
    "\n",
    "        delta_F = np.nan\n",
    "        delta_J = np.nan\n",
    "        if disagree:\n",
    "            F_rank = sub.loc[sub[\"celebrity_name\"] == elim_rank, \"F_norm\"].iloc[0]\n",
    "            F_pct = sub.loc[sub[\"celebrity_name\"] == elim_pct, \"F_norm\"].iloc[0]\n",
    "            delta_F = F_rank - F_pct\n",
    "\n",
    "            J_rank = sub.loc[sub[\"celebrity_name\"] == elim_rank, \"judge_total\"].iloc[0]\n",
    "            J_pct = sub.loc[sub[\"celebrity_name\"] == elim_pct, \"judge_total\"].iloc[0]\n",
    "            delta_J = J_rank - J_pct\n",
    "\n",
    "        rows.append({\n",
    "            \"season\": season,\n",
    "            \"week\": week,\n",
    "            \"eliminated_rank\": elim_rank,\n",
    "            \"eliminated_pct\": elim_pct,\n",
    "            \"eliminated_real\": eliminated_real,\n",
    "            \"disagree\": disagree,\n",
    "            \"delta_F_rank_minus_pct\": delta_F,\n",
    "            \"delta_J_rank_minus_pct\": delta_J,\n",
    "            \"n_contestants\": len(sub),\n",
    "            \"n_real_elims\": len(real_elims),\n",
    "        })\n",
    "\n",
    "    week_results = pd.DataFrame(rows)\n",
    "    return week_results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Global & per-season summaries (disagreement + match rates)\n",
    "# ============================================================\n",
    "\n",
    "def summarize_week_results(week_results: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute global and per-season summary statistics from week_results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_results : DataFrame\n",
    "        Output of simulate_rank_vs_pct().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_global : dict\n",
    "        {\n",
    "            \"total_weeks\",\n",
    "            \"disagree_weeks\",\n",
    "            \"disagreement_rate\",\n",
    "            \"avg_delta_F_rank_minus_pct\",\n",
    "            \"avg_delta_J_rank_minus_pct\",\n",
    "            \"rank_match_real_rate\",\n",
    "            \"pct_match_real_rate\",\n",
    "        }\n",
    "\n",
    "    per_season_disagree : DataFrame\n",
    "        Per-season disagreement statistics.\n",
    "    \"\"\"\n",
    "    total_weeks = len(week_results)\n",
    "    disagree_weeks = week_results[\"disagree\"].sum()\n",
    "    disagreement_rate = disagree_weeks / total_weeks if total_weeks > 0 else np.nan\n",
    "\n",
    "    # Only disagreement weeks\n",
    "    mask_dis = week_results[\"disagree\"]\n",
    "    avg_delta_F = week_results.loc[mask_dis, \"delta_F_rank_minus_pct\"].mean()\n",
    "    avg_delta_J = week_results.loc[mask_dis, \"delta_J_rank_minus_pct\"].mean()\n",
    "\n",
    "    # Only weeks with exactly 1 real elimination\n",
    "    mask_real = week_results[\"eliminated_real\"].notna()\n",
    "    if mask_real.sum() > 0:\n",
    "        rank_match = (\n",
    "            week_results.loc[mask_real, \"eliminated_rank\"]\n",
    "            == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "        ).mean()\n",
    "        pct_match = (\n",
    "            week_results.loc[mask_real, \"eliminated_pct\"]\n",
    "            == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "        ).mean()\n",
    "    else:\n",
    "        rank_match = np.nan\n",
    "        pct_match = np.nan\n",
    "\n",
    "    summary_global = {\n",
    "        \"total_weeks\": int(total_weeks),\n",
    "        \"disagree_weeks\": int(disagree_weeks),\n",
    "        \"disagreement_rate\": disagreement_rate,\n",
    "        \"avg_delta_F_rank_minus_pct\": avg_delta_F,\n",
    "        \"avg_delta_J_rank_minus_pct\": avg_delta_J,\n",
    "        \"rank_match_real_rate\": rank_match,\n",
    "        \"pct_match_real_rate\": pct_match,\n",
    "    }\n",
    "\n",
    "    # Per-season disagreement summary\n",
    "    per_season_disagree = (\n",
    "        week_results\n",
    "        .groupby(\"season\")\n",
    "        .agg(\n",
    "            weeks=(\"week\", \"count\"),\n",
    "            disagree_weeks=(\"disagree\", \"sum\"),\n",
    "            disagreement_rate=(\"disagree\", \"mean\"),\n",
    "            avg_delta_F=(\"delta_F_rank_minus_pct\", \"mean\"),\n",
    "            avg_delta_J=(\"delta_J_rank_minus_pct\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return summary_global, per_season_disagree\n",
    "\n",
    "\n",
    "def compute_per_season_accuracy(week_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-season accuracy of Rank vs Percent methods\n",
    "    relative to actual eliminations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_results : DataFrame\n",
    "        Output of simulate_rank_vs_pct().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    per_season_acc : DataFrame\n",
    "        Columns:\n",
    "          - 'season'\n",
    "          - 'rank_accuracy'\n",
    "          - 'pct_accuracy'\n",
    "          - 'n_real_weeks'\n",
    "    \"\"\"\n",
    "    # Restrict to weeks with exactly 1 real elimination\n",
    "    wr = week_results.copy()\n",
    "    mask_real = wr[\"eliminated_real\"].notna()\n",
    "    wr = wr[mask_real]\n",
    "\n",
    "    def _acc(group: pd.DataFrame):\n",
    "        n = len(group)\n",
    "        if n == 0:\n",
    "            return pd.Series({\n",
    "                \"rank_accuracy\": np.nan,\n",
    "                \"pct_accuracy\": np.nan,\n",
    "                \"n_real_weeks\": 0\n",
    "            })\n",
    "        rank_acc = (group[\"eliminated_rank\"] == group[\"eliminated_real\"]).mean()\n",
    "        pct_acc = (group[\"eliminated_pct\"] == group[\"eliminated_real\"]).mean()\n",
    "        return pd.Series({\n",
    "            \"rank_accuracy\": rank_acc,\n",
    "            \"pct_accuracy\": pct_acc,\n",
    "            \"n_real_weeks\": n\n",
    "        })\n",
    "\n",
    "    per_season_acc = wr.groupby(\"season\").apply(_acc).reset_index()\n",
    "    per_season_acc = per_season_acc.sort_values(\"season\")\n",
    "    return per_season_acc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Zombie analysis (Percent loser who survives)\n",
    "# ============================================================\n",
    "\n",
    "def compute_zombies(df: pd.DataFrame, tol: float = 1e-3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify \"zombie\" contestants:\n",
    "      - Under Percent rule, they are bottom (or effectively tied for bottom),\n",
    "        but in reality they are NOT eliminated in that week.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Same input format as simulate_rank_vs_pct().\n",
    "        Assumes:\n",
    "          - judge_total > 0 means active contestant\n",
    "          - eliminated == 1 marks real elimination.\n",
    "    tol : float\n",
    "        Numerical tolerance for considering someone \"no better than\" the\n",
    "        theoretical percent loser.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zombies_df : DataFrame\n",
    "        Columns:\n",
    "          - 'season', 'week', 'celebrity_name'\n",
    "          - 'judge_total', 'fan_share_hat'\n",
    "          - 'reason'\n",
    "    \"\"\"\n",
    "    zombies = []\n",
    "\n",
    "    for (season, week), sub in df.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Only active contestants (drop judge_total <= 0)\n",
    "        sub = sub[sub[\"judge_total\"] > 0]\n",
    "        if len(sub) < 2:\n",
    "            continue\n",
    "\n",
    "        j = sub[\"judge_total\"].values\n",
    "        f = sub[\"fan_share_hat\"].values\n",
    "\n",
    "        # Percent rule score\n",
    "        j_pct = j / j.sum()\n",
    "        s_pct = j_pct + f\n",
    "\n",
    "        # Theoretical victim: lowest combined percent\n",
    "        min_idx = np.argmin(s_pct)\n",
    "        min_score = s_pct[min_idx]\n",
    "\n",
    "        # Survivors = all with eliminated == 0\n",
    "        survivors = sub[sub[\"eliminated\"] == 0]\n",
    "\n",
    "        for _, row in survivors.iterrows():\n",
    "            my_score = row[\"judge_total\"] / j.sum() + row[\"fan_share_hat\"]\n",
    "            is_bottom = (my_score <= min_score + tol)\n",
    "            if is_bottom:\n",
    "                zombies.append({\n",
    "                    \"season\": season,\n",
    "                    \"week\": week,\n",
    "                    \"celebrity_name\": row[\"celebrity_name\"],\n",
    "                    \"judge_total\": row[\"judge_total\"],\n",
    "                    \"fan_share_hat\": row[\"fan_share_hat\"],\n",
    "                    \"reason\": \"Bottom by Percent but survived\"\n",
    "                })\n",
    "\n",
    "    zombies_df = pd.DataFrame(zombies)\n",
    "    return zombies_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Plotting utilities (per-season accuracy)\n",
    "# ============================================================\n",
    "\n",
    "def _smooth_xy(x: np.ndarray, y: np.ndarray,\n",
    "               n_points: int = 300,\n",
    "               clip_min: float | None = None,\n",
    "               clip_max: float | None = None):\n",
    "    \"\"\"\n",
    "    Helper: smooth (x, y) using cubic B-spline if SciPy available.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    if len(x) < 3 or not HAVE_SCIPY:\n",
    "        return x, y\n",
    "\n",
    "    x_new = np.linspace(x.min(), x.max(), n_points)\n",
    "    try:\n",
    "        spl = make_interp_spline(x, y, k=3)\n",
    "        y_new = spl(x_new)\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            y_new = np.clip(\n",
    "                y_new,\n",
    "                clip_min if clip_min is not None else y_new.min(),\n",
    "                clip_max if clip_max is not None else y_new.max()\n",
    "            )\n",
    "        return x_new, y_new\n",
    "    except Exception:\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def plot_accuracy_by_season(per_season_acc: pd.DataFrame,\n",
    "                            filename: str = \"method_accuracy_comparison_fancy.png\"):\n",
    "    \"\"\"\n",
    "    Fancy plot: per-season Rank vs Percent accuracies with\n",
    "    nice styling, markers, and optional smoothing.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    y_rank  = per_season_acc[\"rank_accuracy\"].values\n",
    "    y_pct   = per_season_acc[\"pct_accuracy\"].values\n",
    "\n",
    "    # --- Base figure style ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f8f9fa\")  # light gray background\n",
    "\n",
    "    # thinner, subtle grid\n",
    "    ax.grid(True, which=\"both\", axis=\"both\", alpha=0.2, linestyle=\"--\", linewidth=0.7)\n",
    "\n",
    "    # small helper: smoothed line + points\n",
    "    def _plot_series(x, y, label, marker, base_color):\n",
    "        # Scatter (actual points)\n",
    "        plt.scatter(x, y,\n",
    "                    s=60,\n",
    "                    marker=marker,\n",
    "                    edgecolor=\"white\",\n",
    "                    linewidth=1.0,\n",
    "                    alpha=0.9,\n",
    "                    label=f\"{label} (data)\")\n",
    "\n",
    "        # Smoothed trend line\n",
    "        x_s, y_s = _smooth_xy(x, y, n_points=300, clip_min=0.0, clip_max=1.0)\n",
    "        plt.plot(x_s, y_s,\n",
    "                 linewidth=2.5,\n",
    "                 alpha=0.9,\n",
    "                 label=f\"{label} (trend)\")\n",
    "\n",
    "    # --- Plot both methods ---\n",
    "    _plot_series(seasons, y_rank, \"Rank Sum Accuracy\", \"o\", \"#e74c3c\")\n",
    "    _plot_series(seasons, y_pct, \"Percent Sum Accuracy\", \"s\", \"#3498db\")\n",
    "\n",
    "    # Horizontal reference lines at 0.5, 0.75, 1.0\n",
    "    for y_ref in [0.5, 0.75, 1.0]:\n",
    "        plt.axhline(y_ref, color=\"gray\", linestyle=\":\", linewidth=0.6, alpha=0.5)\n",
    "\n",
    "    # Titles & labels\n",
    "    plt.title(\"Model Agreement with Reality by Season\\nRank Sum vs Percent Sum\",\n",
    "              fontsize=16, fontweight=\"bold\", pad=10)\n",
    "    plt.xlabel(\"Season\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy (Match Rate)\", fontsize=12)\n",
    "\n",
    "    # X ticks\n",
    "    plt.xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "\n",
    "    # Legend styling\n",
    "    leg = plt.legend(frameon=True, fontsize=10)\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    # Small annotation to explain\n",
    "    plt.text(seasons.min() + 0.2, 0.95,\n",
    "             \"Higher = method matches actual eliminations more often\",\n",
    "             fontsize=9, color=\"#444444\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=250)\n",
    "    plt.close()\n",
    "    print(f\"Saved fancy plot: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuracy_diff_smooth(per_season_acc: pd.DataFrame,\n",
    "                              filename: str = \"method_comparison_diff_fancy.png\"):\n",
    "    \"\"\"\n",
    "    Fancy smoothed difference plot:\n",
    "        diff(season) = Percent accuracy - Rank accuracy.\n",
    "\n",
    "    Positive region (blue)  -> Percent behaves closer to reality.\n",
    "    Negative region (red)   -> Rank behaves closer to reality.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    diff    = per_season_acc[\"pct_accuracy\"].values - per_season_acc[\"rank_accuracy\"].values\n",
    "\n",
    "    x_s, y_s = _smooth_xy(seasons, diff, n_points=300, clip_min=-0.5, clip_max=0.5)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f8f9fa\")\n",
    "    ax.grid(True, which=\"both\", axis=\"both\", alpha=0.2, linestyle=\"--\", linewidth=0.7)\n",
    "\n",
    "    # Baseline at 0\n",
    "    plt.axhline(0, color=\"#333333\", linewidth=1.0, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Smoothed central curve (neutral color)\n",
    "    plt.plot(x_s, y_s, color=\"#555555\", linewidth=1.8, alpha=0.8, label=\"Smoothed gap\")\n",
    "\n",
    "    # Fill regions: Percent better (above 0) vs Rank better (below 0)\n",
    "    plt.fill_between(x_s, 0, y_s, where=(y_s >= 0),\n",
    "                     interpolate=True, color=\"#5dade2\", alpha=0.55,\n",
    "                     label=\"Percent Sum better\")\n",
    "\n",
    "    plt.fill_between(x_s, 0, y_s, where=(y_s <= 0),\n",
    "                     interpolate=True, color=\"#e74c3c\", alpha=0.45,\n",
    "                     label=\"Rank Sum better\")\n",
    "\n",
    "    # Scatter actual season points, colored by sign\n",
    "    colors = [\"#5dade2\" if v >= 0 else \"#e74c3c\" for v in diff]\n",
    "    plt.scatter(seasons, diff,\n",
    "                c=colors,\n",
    "                s=60,\n",
    "                edgecolor=\"white\",\n",
    "                linewidth=1.0,\n",
    "                zorder=5)\n",
    "\n",
    "    # Titles & labels\n",
    "    plt.title(\"Performance Gap by Season\\nPercent Sum vs Rank Sum\",\n",
    "              fontsize=16, fontweight=\"bold\", pad=10)\n",
    "    plt.xlabel(\"Season\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy Difference\\n(Percent Accuracy − Rank Accuracy)\", fontsize=11)\n",
    "\n",
    "    # X ticks\n",
    "    plt.xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "\n",
    "    # Text hints\n",
    "    # Place text based on y-limits to avoid overlap\n",
    "    ymin, ymax = -0.5, 0.5\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    plt.text(seasons.min() + 0.2, ymax - 0.05,\n",
    "             \"↑ Percent Sum matches reality more often\",\n",
    "             fontsize=9, color=\"#1f618d\", va=\"top\")\n",
    "    plt.text(seasons.min() + 0.2, ymin + 0.05,\n",
    "             \"↓ Rank Sum matches reality more often\",\n",
    "             fontsize=9, color=\"#922b21\", va=\"bottom\")\n",
    "\n",
    "    # Highlight a specific season (e.g., 27) if present\n",
    "    if 27 in seasons:\n",
    "        s27_row = per_season_acc[per_season_acc[\"season\"] == 27]\n",
    "        if not s27_row.empty:\n",
    "            s27 = 27\n",
    "            d27 = (s27_row[\"pct_accuracy\"].values[0]\n",
    "                   - s27_row[\"rank_accuracy\"].values[0])\n",
    "            plt.scatter([s27], [d27],\n",
    "                        s=90, edgecolor=\"black\", facecolor=\"yellow\", zorder=10)\n",
    "            plt.annotate(f\"S27: {d27:+.2f}\",\n",
    "                         xy=(s27, d27),\n",
    "                         xytext=(s27 + 0.5, d27 + 0.1),\n",
    "                         fontsize=9,\n",
    "                         arrowprops=dict(arrowstyle=\"->\", color=\"black\"),\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.2\",\n",
    "                                   fc=\"white\", ec=\"#555555\", alpha=0.9))\n",
    "\n",
    "    # Legend\n",
    "    leg = plt.legend(frameon=True, fontsize=10, loc=\"upper right\")\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=250)\n",
    "    plt.close()\n",
    "    print(f\"Saved fancy plot: {filename}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# UMN colors\n",
    "UMN_MAROON = \"#7A0019\"\n",
    "UMN_GOLD   = \"#FFCC33\"\n",
    "\n",
    "def plot_combined_umn(per_season_acc: pd.DataFrame,\n",
    "                      zombies_df: pd.DataFrame,\n",
    "                      filename: str = \"q2_combined_umn.png\"):\n",
    "    \"\"\"\n",
    "    Create a combined 2x1 subplot figure with UMN maroon & gold theme:\n",
    "\n",
    "      Top  subplot: per-season accuracy of Rank vs Percent (lines + points).\n",
    "      Bottom subplot: accuracy gap (Percent - Rank) with shaded regions,\n",
    "                      plus markers for seasons with zombies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    per_season_acc : DataFrame\n",
    "        Output of compute_per_season_accuracy(), with columns:\n",
    "          - 'season'\n",
    "          - 'rank_accuracy'\n",
    "          - 'pct_accuracy'\n",
    "    zombies_df : DataFrame\n",
    "        Output of compute_zombies(), with column:\n",
    "          - 'season'\n",
    "    filename : str\n",
    "        Output PNG name.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    y_rank  = per_season_acc[\"rank_accuracy\"].values\n",
    "    y_pct   = per_season_acc[\"pct_accuracy\"].values\n",
    "\n",
    "    # Accuracy difference: Percent - Rank\n",
    "    diff = y_pct - y_rank\n",
    "    x_s, diff_s = _smooth_xy(seasons, diff,\n",
    "                             n_points=300, clip_min=-0.5, clip_max=0.5)\n",
    "\n",
    "    # Seasons that have at least one zombie\n",
    "    zombie_seasons = sorted(zombies_df[\"season\"].unique()) if not zombies_df.empty else []\n",
    "\n",
    "    # ----------------- Create figure & axes -----------------\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        2, 1, figsize=(14, 10),\n",
    "        sharex=True,\n",
    "        gridspec_kw={\"height_ratios\": [3, 2]}\n",
    "    )\n",
    "\n",
    "    # light gray background\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.set_facecolor(\"#f8f9fa\")\n",
    "        ax.grid(True, which=\"both\", axis=\"both\",\n",
    "                alpha=0.2, linestyle=\"--\", linewidth=0.7)\n",
    "\n",
    "    # ===================== TOP: ACCURACIES =====================\n",
    "    # Smooth lines\n",
    "    x_rank_s, y_rank_s = _smooth_xy(seasons, y_rank,\n",
    "                                    n_points=300, clip_min=0.0, clip_max=1.0)\n",
    "    x_pct_s,  y_pct_s  = _smooth_xy(seasons, y_pct,\n",
    "                                    n_points=300, clip_min=0.0, clip_max=1.0)\n",
    "\n",
    "    ax1.plot(x_rank_s, y_rank_s,\n",
    "             color=UMN_MAROON, linewidth=2.5,\n",
    "             label=\"Rank Sum Accuracy (trend)\")\n",
    "    ax1.plot(x_pct_s, y_pct_s,\n",
    "             color=UMN_GOLD, linewidth=2.5,\n",
    "             label=\"Percent Sum Accuracy (trend)\")\n",
    "\n",
    "    # Scatter actual points\n",
    "    ax1.scatter(seasons, y_rank,\n",
    "                s=55, marker=\"o\", color=UMN_MAROON,\n",
    "                edgecolor=\"white\", linewidth=1.0,\n",
    "                label=\"Rank (data)\")\n",
    "    ax1.scatter(seasons, y_pct,\n",
    "                s=55, marker=\"s\", color=UMN_GOLD,\n",
    "                edgecolor=\"white\", linewidth=1.0,\n",
    "                label=\"Percent (data)\")\n",
    "\n",
    "    # Reference lines at 0.5, 0.75, 1.0\n",
    "    for y_ref in [0.5, 0.75, 1.0]:\n",
    "        ax1.axhline(y_ref, color=\"gray\", linestyle=\":\", linewidth=0.6, alpha=0.5)\n",
    "\n",
    "    ax1.set_title(\n",
    "        \"Model Agreement with Reality by Season\\n\"\n",
    "        \"Rank (Maroon) vs Percent (Gold)\",\n",
    "        fontsize=16, fontweight=\"bold\", pad=10\n",
    "    )\n",
    "    ax1.set_ylabel(\"Accuracy (Match Rate)\", fontsize=12)\n",
    "\n",
    "    leg1 = ax1.legend(frameon=True, fontsize=10, loc=\"lower left\")\n",
    "    leg1.get_frame().set_facecolor(\"white\")\n",
    "    leg1.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg1.get_frame().set_alpha(0.9)\n",
    "\n",
    "    ax1.text(seasons.min() + 0.3, 0.96,\n",
    "             \"Higher = method matches actual eliminations more often\",\n",
    "             fontsize=9, color=\"#444444\")\n",
    "\n",
    "    # ================== BOTTOM: DIFF + ZOMBIES ==================\n",
    "    ax2.axhline(0, color=\"#555555\", linewidth=1.0,\n",
    "                linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Smooth central curve\n",
    "    ax2.plot(x_s, diff_s, color=\"#555555\",\n",
    "             linewidth=1.8, alpha=0.9, label=\"Smoothed gap\")\n",
    "\n",
    "    # Fill regions: Percent better vs Rank better\n",
    "    ax2.fill_between(x_s, 0, diff_s, where=(diff_s >= 0),\n",
    "                     interpolate=True, color=UMN_GOLD, alpha=0.55,\n",
    "                     label=\"Percent Sum better\")\n",
    "    ax2.fill_between(x_s, 0, diff_s, where=(diff_s <= 0),\n",
    "                     interpolate=True, color=UMN_MAROON, alpha=0.45,\n",
    "                     label=\"Rank Sum better\")\n",
    "\n",
    "    # Scatter actual season diffs\n",
    "    colors = [UMN_GOLD if d >= 0 else UMN_MAROON for d in diff]\n",
    "    ax2.scatter(seasons, diff,\n",
    "                c=colors, s=55, edgecolor=\"white\", linewidth=1.0, zorder=5)\n",
    "\n",
    "    # Mark zombie seasons with stars along the diff curve (or near zero if diff is tiny)\n",
    "    for s in zombie_seasons:\n",
    "        if s in per_season_acc[\"season\"].values:\n",
    "            d_val = diff[per_season_acc[\"season\"].values.tolist().index(s)]\n",
    "            # If diff is very small, lift the star slightly so it's visible\n",
    "            y_star = d_val + (0.03 if abs(d_val) < 0.03 else 0.0)\n",
    "            ax2.scatter(s, y_star,\n",
    "                        marker=\"*\", s=150,\n",
    "                        color=\"#000000\", edgecolor=\"white\",\n",
    "                        linewidth=1.0, zorder=10)\n",
    "    if zombie_seasons:\n",
    "        ax2.text(seasons.min() + 0.3, 0.46,\n",
    "                 \"★ Seasons with 'zombie' contestants\\n\"\n",
    "                 \"(bottom by Percent but not eliminated)\",\n",
    "                 fontsize=9, color=\"#000000\")\n",
    "\n",
    "    # Annotate Percent better / Rank better regions\n",
    "    ymin, ymax = -0.5, 0.5\n",
    "    ax2.set_ylim(ymin, ymax)\n",
    "\n",
    "    ax2.text(seasons.min() + 0.3, ymax - 0.05,\n",
    "             \"↑ Percent Sum matches reality more often\",\n",
    "             fontsize=9, color=\"#555555\", va=\"top\")\n",
    "    ax2.text(seasons.min() + 0.3, ymin + 0.05,\n",
    "             \"↓ Rank Sum matches reality more often\",\n",
    "             fontsize=9, color=\"#555555\", va=\"bottom\")\n",
    "\n",
    "    # Optional: highlight Season 27 if present\n",
    "    if 27 in seasons:\n",
    "        idx27 = per_season_acc[per_season_acc[\"season\"] == 27].index[0]\n",
    "        s27 = 27\n",
    "        d27 = diff[idx27]\n",
    "        ax2.scatter([s27], [d27],\n",
    "                    s=140, edgecolor=\"black\",\n",
    "                    facecolor=\"#ffff88\", zorder=11)\n",
    "        ax2.annotate(f\"S27: {d27:+.2f}\",\n",
    "                     xy=(s27, d27),\n",
    "                     xytext=(s27 + 0.6, d27 + 0.12),\n",
    "                     fontsize=9,\n",
    "                     arrowprops=dict(arrowstyle=\"->\", color=\"black\"),\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.2\",\n",
    "                               fc=\"white\", ec=\"#555555\", alpha=0.9))\n",
    "\n",
    "    ax2.set_xlabel(\"Season\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Accuracy Difference\\n(Percent − Rank)\", fontsize=11)\n",
    "    ax2.set_xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "\n",
    "    leg2 = ax2.legend(frameon=True, fontsize=10, loc=\"lower right\")\n",
    "    leg2.get_frame().set_facecolor(\"white\")\n",
    "    leg2.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg2.get_frame().set_alpha(0.9)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filename, dpi=260)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved combined UMN-style plot: {filename}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Script entry point: tie everything together\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        df = pd.read_csv(\"fan_shares_estimated.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Could not find fan_shares_estimated.csv. \"\n",
    "              \"Please run your Q1 model first.\")\n",
    "        return\n",
    "\n",
    "    # 1) Simulate rank vs percent\n",
    "    week_results = simulate_rank_vs_pct(df)\n",
    "\n",
    "    # 2) Global + per-season disagreement summary\n",
    "    summary_global, per_season_disagree = summarize_week_results(week_results)\n",
    "    print(\"=== Global summary (Rank vs Percent) ===\")\n",
    "    for k, v in summary_global.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n=== Per-season disagreement summary (head) ===\")\n",
    "    print(per_season_disagree.head().to_string(index=False))\n",
    "\n",
    "    # 3) Zombie analysis (Percent losers who survived)\n",
    "    zombies_df = compute_zombies(df, tol=1e-3)\n",
    "    print(\"\\n=== Zombies under Percent rule (head) ===\")\n",
    "    print(zombies_df.head(10).to_string(index=False))\n",
    "\n",
    "    # Optionally highlight specific controversial contestants\n",
    "    targets = [\"Jerry Rice\", \"Billy Ray Cyrus\", \"Bristol Palin\", \"Bobby Bones\"]\n",
    "    z_targets = zombies_df[zombies_df[\"celebrity_name\"].isin(targets)]\n",
    "    if not z_targets.empty:\n",
    "        print(\"\\n=== Zombies among controversial contestants ===\")\n",
    "        print(z_targets.to_string(index=False))\n",
    "\n",
    "    # 4) Per-season accuracy and plots\n",
    "    per_season_acc = compute_per_season_accuracy(week_results)\n",
    "    plot_combined_umn(per_season_acc, zombies_df,\n",
    "                      filename=\"q2_combined_umn.png\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7c2e8",
   "metadata": {},
   "source": [
    "## Question 2 Analysis: Comparing Rank, Percent, and BT+Judge Rules\n",
    "\n",
    "This module implements the full analysis pipeline for **MCM 2026 Problem C – Question 2 (Part 1)**, assuming that fan vote shares from Question 1 have already been estimated and saved in `fan_shares_estimated.csv`.\n",
    "\n",
    "Each row of `fan_shares_estimated.csv` is a `(season, week, contestant)` record with:\n",
    "- `season`, `week`, `celebrity_name`\n",
    "- `judge_total` — total judges’ score for that week\n",
    "- `fan_share_hat` — reconstructed fan vote share\n",
    "- `eliminated` — 1 if the contestant was eliminated that week, 0 otherwise\n",
    "\n",
    "The module provides:\n",
    "\n",
    "- **Simulation of three elimination rules** for every `(season, week)`:\n",
    "  - **Rank-Sum**: rank by judges and fans, eliminate the worst combined rank.\n",
    "  - **Percent-Sum**: add judge percentage + fan share, eliminate the lowest total.\n",
    "  - **Bottom-Two + Judge (BT+J)**: take bottom two by Percent-Sum, then eliminate the one with the lower judge score.\n",
    "\n",
    "- **Global and per-season summaries**:\n",
    "  - Disagreement rate between Rank-Sum and Percent-Sum.\n",
    "  - Average fan-share and judge-score gaps when the rules disagree.\n",
    "  - Match rates of Rank, Percent, and BT+J against the actual historical eliminations.\n",
    "\n",
    "- **Zombie analysis**:\n",
    "  - Identification of “zombie” contestants who would be eliminated by Percent-Sum but survive in the real show.\n",
    "\n",
    "- **Controversy scores**:\n",
    "  - Per-contestant judge–fan rank disagreement across weeks.\n",
    "\n",
    "- **Placement comparisons**:\n",
    "  - For each contestant in each season, compute final placement under:\n",
    "    - observed show,\n",
    "    - Rank-Sum,\n",
    "    - Percent-Sum,\n",
    "    - BT+Judge.\n",
    "\n",
    "- **Publication-ready plots**:\n",
    "  - Season-by-season accuracy gaps relative to Rank-Sum.\n",
    "  - Overall mean accuracy (with error bars) for all three rules.\n",
    "  - Placement comparison for selected “extraordinary” contestants (e.g., Jerry Rice, Billy Ray Cyrus, Bristol Palin, Bobby Bones).\n",
    "\n",
    "Running\n",
    "\n",
    "```bash\n",
    "python analysis_q2.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a814d3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Polished `analysis_q2.py`\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "analysis_q2.py\n",
    "\n",
    "Analysis utilities for 2026 MCM Problem C – Question 2 (Part 1).\n",
    "\n",
    "This module assumes you have already run your Question 1 fan model and\n",
    "saved its output as `fan_shares_estimated.csv`, with at least:\n",
    "\n",
    "Columns (per row = contestant-season-week):\n",
    "    - season           (int)\n",
    "    - week             (int)\n",
    "    - celebrity_name   (str)\n",
    "    - judge_total      (float)  # total judge score for that week\n",
    "    - fan_share_hat    (float)  # estimated fan share for that week\n",
    "    - eliminated       (0/1)    # 1 if actually eliminated in this week, else 0\n",
    "\n",
    "Core features:\n",
    "    - Simulate rank-based, percent-based, and Bottom-Two+Judge rules.\n",
    "    - Compute disagreement rates and fan/judge differences.\n",
    "    - Compute how often each method matches real eliminations.\n",
    "    - Identify “zombie” contestants (should die under Percent, but survive).\n",
    "    - Compute placements under each rule and compare controversial cases.\n",
    "    - Plot per-season accuracies and accuracy gaps across rules.\n",
    "\n",
    "Usage (as a script):\n",
    "    python analysis_q2.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    # Optional smoothing if SciPy is available\n",
    "    from scipy.interpolate import make_interp_spline\n",
    "\n",
    "    HAVE_SCIPY = True\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 1. Core simulation: Rank vs Percent vs Bottom-two + Judge (BT+J)\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def simulate_all_methods(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate three elimination mechanisms week by week:\n",
    "\n",
    "      - Rank rule    -> eliminated_rank\n",
    "      - Percent rule -> eliminated_pct\n",
    "      - BT+J rule    -> eliminated_btj\n",
    "        (Bottom-two by Percent, then judges eliminate the lower judge_total)\n",
    "\n",
    "    Also records the observed elimination (if exactly one).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Must contain:\n",
    "          - 'season', 'week', 'celebrity_name'\n",
    "          - 'judge_total', 'fan_share_hat', 'eliminated'\n",
    "\n",
    "        Each row should be a (season, week, contestant) where the contestant\n",
    "        is still active in that week.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    week_results : DataFrame\n",
    "        One row per (season, week) with:\n",
    "          - 'season', 'week'\n",
    "          - 'eliminated_rank'\n",
    "          - 'eliminated_pct'\n",
    "          - 'eliminated_btj'\n",
    "          - 'eliminated_real'\n",
    "          - 'disagree_rank_pct'   (Rank vs Percent)\n",
    "          - 'disagree_pct_btj'    (Percent vs BT+J)\n",
    "          - 'delta_F_rank_minus_pct'\n",
    "          - 'delta_J_rank_minus_pct'\n",
    "          - 'n_contestants'\n",
    "          - 'n_real_elims'\n",
    "    \"\"\"\n",
    "    rows: list[dict] = []\n",
    "\n",
    "    for (season, week), sub in df.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Drop rows missing key info\n",
    "        sub = sub.dropna(subset=[\"judge_total\", \"fan_share_hat\"])\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # Normalize fan shares within this week (safety)\n",
    "        total_fan = sub[\"fan_share_hat\"].sum()\n",
    "        if total_fan <= 0 or np.isnan(total_fan):\n",
    "            continue\n",
    "        sub[\"F_norm\"] = sub[\"fan_share_hat\"] / total_fan\n",
    "\n",
    "        # ---------------- Rank rule ----------------\n",
    "        # Higher judge_total => better (rank 1)\n",
    "        sub[\"r_judge\"] = sub[\"judge_total\"].rank(\n",
    "            ascending=False, method=\"min\"\n",
    "        )\n",
    "        # Higher fan share => better (rank 1)\n",
    "        sub[\"r_fan\"] = sub[\"F_norm\"].rank(\n",
    "            ascending=False, method=\"min\"\n",
    "        )\n",
    "        sub[\"S_rank\"] = sub[\"r_judge\"] + sub[\"r_fan\"]\n",
    "\n",
    "        idx_rank = sub[\"S_rank\"].idxmax()\n",
    "        elim_rank = sub.loc[idx_rank, \"celebrity_name\"]\n",
    "\n",
    "        # ---------------- Percent rule ----------------\n",
    "        judge_sum = sub[\"judge_total\"].sum()\n",
    "        if judge_sum <= 0:\n",
    "            # Degenerate week, skip\n",
    "            continue\n",
    "\n",
    "        sub[\"P_judge\"] = sub[\"judge_total\"] / judge_sum\n",
    "        sub[\"S_pct\"] = sub[\"P_judge\"] + sub[\"F_norm\"]\n",
    "\n",
    "        idx_pct = sub[\"S_pct\"].idxmin()\n",
    "        elim_pct = sub.loc[idx_pct, \"celebrity_name\"]\n",
    "\n",
    "        # ---------------- Bottom-two + Judge (BT+J) ----------------\n",
    "        # Bottom two by Percent score\n",
    "        sub_sorted = sub.sort_values(\"S_pct\", ascending=True)\n",
    "        bottom2 = sub_sorted.head(2).copy()\n",
    "\n",
    "        # Judges eliminate the one with LOWER judge_total\n",
    "        idx_btj_row = bottom2[\"judge_total\"].idxmin()\n",
    "        elim_btj = sub.loc[idx_btj_row, \"celebrity_name\"]\n",
    "\n",
    "        # ---------------- Real elimination ----------------\n",
    "        eliminated_rows = sub[sub.get(\"eliminated\", 0) == 1]\n",
    "        real_elims = eliminated_rows[\"celebrity_name\"].tolist()\n",
    "        eliminated_real = real_elims[0] if len(real_elims) == 1 else None\n",
    "\n",
    "        # ---------------- Disagreement stats ----------------\n",
    "        disagree_rank_pct = (elim_rank != elim_pct)\n",
    "        disagree_pct_btj = (elim_pct != elim_btj)\n",
    "\n",
    "        delta_F = np.nan\n",
    "        delta_J = np.nan\n",
    "        if disagree_rank_pct:\n",
    "            F_rank = sub.loc[\n",
    "                sub[\"celebrity_name\"] == elim_rank, \"F_norm\"\n",
    "            ].iloc[0]\n",
    "            F_pct = sub.loc[\n",
    "                sub[\"celebrity_name\"] == elim_pct, \"F_norm\"\n",
    "            ].iloc[0]\n",
    "            delta_F = F_rank - F_pct\n",
    "\n",
    "            J_rank = sub.loc[\n",
    "                sub[\"celebrity_name\"] == elim_rank, \"judge_total\"\n",
    "            ].iloc[0]\n",
    "            J_pct = sub.loc[\n",
    "                sub[\"celebrity_name\"] == elim_pct, \"judge_total\"\n",
    "            ].iloc[0]\n",
    "            delta_J = J_rank - J_pct\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"season\": season,\n",
    "                \"week\": week,\n",
    "                \"eliminated_rank\": elim_rank,\n",
    "                \"eliminated_pct\": elim_pct,\n",
    "                \"eliminated_btj\": elim_btj,\n",
    "                \"eliminated_real\": eliminated_real,\n",
    "                \"disagree_rank_pct\": disagree_rank_pct,\n",
    "                \"disagree_pct_btj\": disagree_pct_btj,\n",
    "                \"delta_F_rank_minus_pct\": delta_F,\n",
    "                \"delta_J_rank_minus_pct\": delta_J,\n",
    "                \"n_contestants\": len(sub),\n",
    "                \"n_real_elims\": len(real_elims),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2. Global & per-season summaries (disagreement + match rates)\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def summarize_week_results(\n",
    "    week_results: pd.DataFrame,\n",
    ") -> tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute global and per-season summary statistics from week_results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_results : DataFrame\n",
    "        Output of simulate_all_methods().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_global : dict\n",
    "        {\n",
    "            \"total_weeks\",\n",
    "            \"disagree_weeks\",\n",
    "            \"disagreement_rate\",\n",
    "            \"avg_delta_F_rank_minus_pct\",\n",
    "            \"avg_delta_J_rank_minus_pct\",\n",
    "            \"rank_match_real_rate\",\n",
    "            \"pct_match_real_rate\",\n",
    "        }\n",
    "\n",
    "    per_season_disagree : DataFrame\n",
    "        Per-season disagreement statistics (Rank vs Percent).\n",
    "    \"\"\"\n",
    "    total_weeks = len(week_results)\n",
    "\n",
    "    # Use the Rank vs Percent disagreement flag\n",
    "    disagree_col = \"disagree_rank_pct\"\n",
    "\n",
    "    disagree_weeks = week_results[disagree_col].sum()\n",
    "    disagreement_rate = (\n",
    "        disagree_weeks / total_weeks if total_weeks > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    # Only disagreement weeks\n",
    "    mask_dis = week_results[disagree_col]\n",
    "    avg_delta_F = week_results.loc[\n",
    "        mask_dis, \"delta_F_rank_minus_pct\"\n",
    "    ].mean()\n",
    "    avg_delta_J = week_results.loc[\n",
    "        mask_dis, \"delta_J_rank_minus_pct\"\n",
    "    ].mean()\n",
    "\n",
    "    # Only weeks with exactly one real elimination\n",
    "    mask_real = week_results[\"eliminated_real\"].notna()\n",
    "    if mask_real.sum() > 0:\n",
    "        rank_match = (\n",
    "            week_results.loc[mask_real, \"eliminated_rank\"]\n",
    "            == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "        ).mean()\n",
    "        pct_match = (\n",
    "            week_results.loc[mask_real, \"eliminated_pct\"]\n",
    "            == week_results.loc[mask_real, \"eliminated_real\"]\n",
    "        ).mean()\n",
    "    else:\n",
    "        rank_match = np.nan\n",
    "        pct_match = np.nan\n",
    "\n",
    "    summary_global = {\n",
    "        \"total_weeks\": int(total_weeks),\n",
    "        \"disagree_weeks\": int(disagree_weeks),\n",
    "        \"disagreement_rate\": disagreement_rate,\n",
    "        \"avg_delta_F_rank_minus_pct\": avg_delta_F,\n",
    "        \"avg_delta_J_rank_minus_pct\": avg_delta_J,\n",
    "        \"rank_match_real_rate\": rank_match,\n",
    "        \"pct_match_real_rate\": pct_match,\n",
    "    }\n",
    "\n",
    "    # Per-season disagreement summary (Rank vs Percent)\n",
    "    per_season_disagree = (\n",
    "        week_results.groupby(\"season\")\n",
    "        .agg(\n",
    "            weeks=(\"week\", \"count\"),\n",
    "            disagree_weeks=(disagree_col, \"sum\"),\n",
    "            disagreement_rate=(disagree_col, \"mean\"),\n",
    "            avg_delta_F=(\"delta_F_rank_minus_pct\", \"mean\"),\n",
    "            avg_delta_J=(\"delta_J_rank_minus_pct\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return summary_global, per_season_disagree\n",
    "\n",
    "\n",
    "def compute_per_season_accuracy(week_results: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-season accuracy of Rank vs Percent vs BT+J methods\n",
    "    relative to actual eliminations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_results : DataFrame\n",
    "        Output of simulate_all_methods().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    per_season_acc : DataFrame\n",
    "        Columns:\n",
    "          - 'season'\n",
    "          - 'rank_accuracy'\n",
    "          - 'pct_accuracy'\n",
    "          - 'btj_accuracy'\n",
    "          - 'n_real_weeks'\n",
    "    \"\"\"\n",
    "    wr = week_results.copy()\n",
    "    # Use only weeks with exactly one observed elimination\n",
    "    wr = wr[wr[\"eliminated_real\"].notna()]\n",
    "\n",
    "    if wr.empty:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"season\",\n",
    "                \"rank_accuracy\",\n",
    "                \"pct_accuracy\",\n",
    "                \"btj_accuracy\",\n",
    "                \"n_real_weeks\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    wr[\"rank_correct\"] = wr[\"eliminated_rank\"] == wr[\"eliminated_real\"]\n",
    "    wr[\"pct_correct\"] = wr[\"eliminated_pct\"] == wr[\"eliminated_real\"]\n",
    "    wr[\"btj_correct\"] = wr[\"eliminated_btj\"] == wr[\"eliminated_real\"]\n",
    "\n",
    "    per_season_acc = (\n",
    "        wr.groupby(\"season\")\n",
    "        .agg(\n",
    "            rank_accuracy=(\"rank_correct\", \"mean\"),\n",
    "            pct_accuracy=(\"pct_correct\", \"mean\"),\n",
    "            btj_accuracy=(\"btj_correct\", \"mean\"),\n",
    "            n_real_weeks=(\"week\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(\"season\")\n",
    "    )\n",
    "\n",
    "    return per_season_acc\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 3. Zombie analysis (Percent loser who survives)\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def compute_zombies(df: pd.DataFrame, tol: float = 1e-3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identify 'zombie' contestants:\n",
    "      - Under Percent rule (S_pct) they are bottom (or tied at bottom),\n",
    "      - But in reality they are NOT eliminated that week.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Must have: 'season', 'week', 'celebrity_name',\n",
    "                   'judge_total', 'fan_share_hat', 'eliminated'\n",
    "    tol : float\n",
    "        Numerical tolerance when comparing scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    zombies_df : DataFrame\n",
    "        Columns: season, week, celebrity_name, judge_total, fan_share_hat, reason\n",
    "    \"\"\"\n",
    "    zombies: list[dict] = []\n",
    "\n",
    "    for (season, week), sub in df.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "\n",
    "        # Only active contestants (judge_total > 0)\n",
    "        sub = sub[sub[\"judge_total\"] > 0]\n",
    "        if len(sub) < 2:\n",
    "            continue\n",
    "\n",
    "        j = sub[\"judge_total\"].values\n",
    "        f = sub[\"fan_share_hat\"].values\n",
    "\n",
    "        # Percent score\n",
    "        j_pct = j / j.sum()\n",
    "        s_pct = j_pct + f\n",
    "\n",
    "        # Index of theoretical victim by Percent rule\n",
    "        min_idx = np.argmin(s_pct)\n",
    "        min_score = s_pct[min_idx]\n",
    "\n",
    "        # Real elimination(s) that week\n",
    "        eliminated_rows = sub[sub[\"eliminated\"] == 1]\n",
    "        real_elims = eliminated_rows[\"celebrity_name\"].tolist()\n",
    "\n",
    "        # Any contestant whose S_pct <= min_score + tol but NOT eliminated\n",
    "        for _, row in sub.iterrows():\n",
    "            my_score = (\n",
    "                row[\"judge_total\"] / j.sum() + row[\"fan_share_hat\"]\n",
    "            )\n",
    "            is_bottom = my_score <= min_score + tol\n",
    "            if is_bottom and (row[\"celebrity_name\"] not in real_elims):\n",
    "                zombies.append(\n",
    "                    {\n",
    "                        \"season\": season,\n",
    "                        \"week\": week,\n",
    "                        \"celebrity_name\": row[\"celebrity_name\"],\n",
    "                        \"judge_total\": row[\"judge_total\"],\n",
    "                        \"fan_share_hat\": row[\"fan_share_hat\"],\n",
    "                        \"reason\": \"Bottom by Percent but survived\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(zombies)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 4. Judge–fan controversy measure\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def compute_controversy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute judge–fan controversy scores for each contestant in each season.\n",
    "\n",
    "    For each (season, week), we compute:\n",
    "        R_J = rank of judge_total (1 = highest)\n",
    "        R_F = rank of fan_share_hat (1 = highest)\n",
    "        D   = R_J - R_F\n",
    "\n",
    "    Then we aggregate over weeks:\n",
    "        mean_abs_D = mean |D|\n",
    "        max_abs_D  = max |D|\n",
    "        weeks_active = number of weeks the contestant appeared.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    Ds = []\n",
    "    for (season, week), sub in df.groupby([\"season\", \"week\"]):\n",
    "        sub = sub.copy()\n",
    "        sub = sub.dropna(subset=[\"judge_total\", \"fan_share_hat\"])\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        sub[\"R_J\"] = sub[\"judge_total\"].rank(ascending=False, method=\"min\")\n",
    "        sub[\"R_F\"] = sub[\"fan_share_hat\"].rank(\n",
    "            ascending=False, method=\"min\"\n",
    "        )\n",
    "        sub[\"D\"] = sub[\"R_J\"] - sub[\"R_F\"]\n",
    "        Ds.append(sub[[\"season\", \"week\", \"celebrity_name\", \"D\"]])\n",
    "\n",
    "    if not Ds:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"season\",\n",
    "                \"celebrity_name\",\n",
    "                \"mean_abs_D\",\n",
    "                \"max_abs_D\",\n",
    "                \"weeks_active\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    D_df = pd.concat(Ds, ignore_index=True)\n",
    "    D_df[\"absD\"] = D_df[\"D\"].abs()\n",
    "\n",
    "    cont_df = (\n",
    "        D_df.groupby([\"season\", \"celebrity_name\"])\n",
    "        .agg(\n",
    "            mean_abs_D=(\"absD\", \"mean\"),\n",
    "            max_abs_D=(\"absD\", \"max\"),\n",
    "            weeks_active=(\"D\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return cont_df\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 5. Compute placements per season and method\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def compute_placements_per_season(\n",
    "    week_results: pd.DataFrame, df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each season and contestant, compute elimination week and placement\n",
    "    under each method: observed, Rank, Percent, BT+J.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_results : DataFrame\n",
    "        Output of simulate_all_methods().\n",
    "        Must have: 'season','week','eliminated_rank','eliminated_pct',\n",
    "                   'eliminated_btj','eliminated_real'\n",
    "    df : DataFrame\n",
    "        Original panel to know which contestants participated in each season.\n",
    "        Must have: 'season','celebrity_name'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    placement_df : DataFrame\n",
    "        Columns:\n",
    "          - season, celebrity_name\n",
    "          - elim_week_obs, elim_week_rank, elim_week_pct, elim_week_btj\n",
    "          - place_obs, place_rank, place_pct, place_btj\n",
    "    \"\"\"\n",
    "    # All contestants per season\n",
    "    contestants = (\n",
    "        df.groupby(\"season\")[\"celebrity_name\"]\n",
    "        .unique()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"celebrity_name\": \"contestants\"})\n",
    "    )\n",
    "\n",
    "    records: list[dict] = []\n",
    "\n",
    "    for _, row in contestants.iterrows():\n",
    "        season = row[\"season\"]\n",
    "        names = row[\"contestants\"]\n",
    "\n",
    "        wr_s = week_results[week_results[\"season\"] == season].copy()\n",
    "        if wr_s.empty:\n",
    "            continue\n",
    "\n",
    "        # For quick lookup: week -> elim name for each method\n",
    "        elim_obs = wr_s.set_index(\"week\")[\"eliminated_real\"].to_dict()\n",
    "        elim_rank = wr_s.set_index(\"week\")[\"eliminated_rank\"].to_dict()\n",
    "        elim_pct = wr_s.set_index(\"week\")[\"eliminated_pct\"].to_dict()\n",
    "        elim_btj = wr_s.set_index(\"week\")[\"eliminated_btj\"].to_dict()\n",
    "\n",
    "        weeks_sorted = sorted(wr_s[\"week\"].unique())\n",
    "\n",
    "        # Compute elimination week for each contestant under each method\n",
    "        elim_week: dict[str, dict[str, int]] = {\n",
    "            m: {} for m in [\"obs\", \"rank\", \"pct\", \"btj\"]\n",
    "        }\n",
    "\n",
    "        last_week = max(weeks_sorted)\n",
    "\n",
    "        for name in names:\n",
    "            # Observed\n",
    "            tw_obs = [w for w in weeks_sorted if elim_obs.get(w) == name]\n",
    "            elim_week[\"obs\"][name] = tw_obs[0] if tw_obs else last_week\n",
    "\n",
    "            # Rank\n",
    "            tw_rank = [w for w in weeks_sorted if elim_rank.get(w) == name]\n",
    "            elim_week[\"rank\"][name] = tw_rank[0] if tw_rank else last_week\n",
    "\n",
    "            # Percent\n",
    "            tw_pct = [w for w in weeks_sorted if elim_pct.get(w) == name]\n",
    "            elim_week[\"pct\"][name] = tw_pct[0] if tw_pct else last_week\n",
    "\n",
    "            # BT+J\n",
    "            tw_btj = [w for w in weeks_sorted if elim_btj.get(w) == name]\n",
    "            elim_week[\"btj\"][name] = tw_btj[0] if tw_btj else last_week\n",
    "\n",
    "        # Convert elimination weeks to placements (1 = winner)\n",
    "        for name in names:\n",
    "            rec = {\n",
    "                \"season\": season,\n",
    "                \"celebrity_name\": name,\n",
    "                \"elim_week_obs\": elim_week[\"obs\"][name],\n",
    "                \"elim_week_rank\": elim_week[\"rank\"][name],\n",
    "                \"elim_week_pct\": elim_week[\"pct\"][name],\n",
    "                \"elim_week_btj\": elim_week[\"btj\"][name],\n",
    "            }\n",
    "            for m in [\"obs\", \"rank\", \"pct\", \"btj\"]:\n",
    "                wk_i = elim_week[m][name]\n",
    "                num_before = sum(\n",
    "                    1 for other in names if elim_week[m][other] < wk_i\n",
    "                )\n",
    "                rec[f\"place_{m}\"] = 1 + num_before\n",
    "\n",
    "            records.append(rec)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 6. Plotting utilities\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def _smooth_xy(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_points: int = 300,\n",
    "    clip_min: float | None = None,\n",
    "    clip_max: float | None = None,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Helper: smooth (x, y) using a cubic B-spline if SciPy is available.\n",
    "\n",
    "    If SciPy is not available or there are too few points, returns (x, y).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    if len(x) < 3 or not HAVE_SCIPY:\n",
    "        return x, y\n",
    "\n",
    "    x_new = np.linspace(x.min(), x.max(), n_points)\n",
    "    try:\n",
    "        spl = make_interp_spline(x, y, k=3)\n",
    "        y_new = spl(x_new)\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            y_new = np.clip(\n",
    "                y_new,\n",
    "                clip_min if clip_min is not None else y_new.min(),\n",
    "                clip_max if clip_max is not None else y_new.max(),\n",
    "            )\n",
    "        return x_new, y_new\n",
    "    except Exception:  # pragma: no cover - robust to spline exceptions\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def plot_accuracy_by_season(\n",
    "    per_season_acc: pd.DataFrame,\n",
    "    filename: str = \"method_accuracy_comparison_fancy.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot per-season Rank vs Percent accuracies with clean styling and\n",
    "    optional smoothing.\n",
    "\n",
    "    This version only uses Rank vs Percent and is left here for\n",
    "    backward compatibility; newer plots use all three methods.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    y_rank = per_season_acc[\"rank_accuracy\"].values\n",
    "    y_pct = per_season_acc[\"pct_accuracy\"].values\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f8f9fa\")\n",
    "    ax.grid(\n",
    "        True, which=\"both\", axis=\"both\", alpha=0.2, linestyle=\"--\", linewidth=0.7\n",
    "    )\n",
    "\n",
    "    def _plot_series(x, y, label, marker):\n",
    "        # Scatter (actual points)\n",
    "        plt.scatter(\n",
    "            x,\n",
    "            y,\n",
    "            s=60,\n",
    "            marker=marker,\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=1.0,\n",
    "            alpha=0.9,\n",
    "            label=f\"{label} (data)\",\n",
    "        )\n",
    "\n",
    "        # Smoothed trend line\n",
    "        x_s, y_s = _smooth_xy(x, y, n_points=300, clip_min=0.0, clip_max=1.0)\n",
    "        plt.plot(\n",
    "            x_s,\n",
    "            y_s,\n",
    "            linewidth=2.5,\n",
    "            alpha=0.9,\n",
    "            label=f\"{label} (trend)\",\n",
    "        )\n",
    "\n",
    "    _plot_series(seasons, y_rank, \"Rank Sum Accuracy\", \"o\")\n",
    "    _plot_series(seasons, y_pct, \"Percent Sum Accuracy\", \"s\")\n",
    "\n",
    "    for y_ref in [0.5, 0.75, 1.0]:\n",
    "        plt.axhline(y_ref, color=\"gray\", linestyle=\":\", linewidth=0.6, alpha=0.5)\n",
    "\n",
    "    plt.title(\n",
    "        \"Model Agreement with Reality by Season\\nRank Sum vs Percent Sum\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=10,\n",
    "    )\n",
    "    plt.xlabel(\"Season\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy (Match Rate)\", fontsize=12)\n",
    "\n",
    "    plt.xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "\n",
    "    leg = plt.legend(frameon=True, fontsize=10)\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    plt.text(\n",
    "        seasons.min() + 0.2,\n",
    "        0.95,\n",
    "        \"Higher = method matches actual eliminations more often\",\n",
    "        fontsize=9,\n",
    "        color=\"#444444\",\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=250)\n",
    "    plt.close()\n",
    "    print(f\"Saved fancy plot: {filename}\")\n",
    "\n",
    "\n",
    "def plot_accuracy_diff_smooth(\n",
    "    per_season_acc: pd.DataFrame,\n",
    "    filename: str = \"method_comparison_diff_fancy.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Smoothed difference plot:\n",
    "        diff(season) = Percent accuracy - Rank accuracy.\n",
    "\n",
    "    Positive region  -> Percent behaves closer to reality.\n",
    "    Negative region  -> Rank behaves closer to reality.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    diff = (\n",
    "        per_season_acc[\"pct_accuracy\"].values\n",
    "        - per_season_acc[\"rank_accuracy\"].values\n",
    "    )\n",
    "\n",
    "    x_s, y_s = _smooth_xy(\n",
    "        seasons, diff, n_points=300, clip_min=-0.5, clip_max=0.5\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f8f9fa\")\n",
    "    ax.grid(\n",
    "        True, which=\"both\", axis=\"both\", alpha=0.2, linestyle=\"--\", linewidth=0.7\n",
    "    )\n",
    "\n",
    "    plt.axhline(0, color=\"#333333\", linewidth=1.0, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.plot(\n",
    "        x_s, y_s, color=\"#555555\", linewidth=1.8, alpha=0.8, label=\"Smoothed gap\"\n",
    "    )\n",
    "\n",
    "    plt.fill_between(\n",
    "        x_s,\n",
    "        0,\n",
    "        y_s,\n",
    "        where=(y_s >= 0),\n",
    "        interpolate=True,\n",
    "        color=\"#5dade2\",\n",
    "        alpha=0.55,\n",
    "        label=\"Percent Sum better\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        x_s,\n",
    "        0,\n",
    "        y_s,\n",
    "        where=(y_s <= 0),\n",
    "        interpolate=True,\n",
    "        color=\"#e74c3c\",\n",
    "        alpha=0.45,\n",
    "        label=\"Rank Sum better\",\n",
    "    )\n",
    "\n",
    "    colors = [\"#5dade2\" if v >= 0 else \"#e74c3c\" for v in diff]\n",
    "    plt.scatter(\n",
    "        seasons,\n",
    "        diff,\n",
    "        c=colors,\n",
    "        s=60,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    plt.title(\n",
    "        \"Performance Gap by Season\\nPercent Sum vs Rank Sum\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        pad=10,\n",
    "    )\n",
    "    plt.xlabel(\"Season\", fontsize=12)\n",
    "    plt.ylabel(\n",
    "        \"Accuracy Difference\\n(Percent Accuracy − Rank Accuracy)\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "\n",
    "    plt.xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "\n",
    "    ymin, ymax = -0.5, 0.5\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    plt.text(\n",
    "        seasons.min() + 0.2,\n",
    "        ymax - 0.05,\n",
    "        \"↑ Percent Sum matches reality more often\",\n",
    "        fontsize=9,\n",
    "        color=\"#1f618d\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    plt.text(\n",
    "        seasons.min() + 0.2,\n",
    "        ymin + 0.05,\n",
    "        \"↓ Rank Sum matches reality more often\",\n",
    "        fontsize=9,\n",
    "        color=\"#922b21\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    if 27 in seasons:\n",
    "        s27_row = per_season_acc[per_season_acc[\"season\"] == 27]\n",
    "        if not s27_row.empty:\n",
    "            s27 = 27\n",
    "            d27 = (\n",
    "                s27_row[\"pct_accuracy\"].values[0]\n",
    "                - s27_row[\"rank_accuracy\"].values[0]\n",
    "            )\n",
    "            plt.scatter(\n",
    "                [s27],\n",
    "                [d27],\n",
    "                s=90,\n",
    "                edgecolor=\"black\",\n",
    "                facecolor=\"yellow\",\n",
    "                zorder=10,\n",
    "            )\n",
    "            plt.annotate(\n",
    "                f\"S27: {d27:+.2f}\",\n",
    "                xy=(s27, d27),\n",
    "                xytext=(s27 + 0.5, d27 + 0.1),\n",
    "                fontsize=9,\n",
    "                arrowprops=dict(arrowstyle=\"->\", color=\"black\"),\n",
    "                bbox=dict(\n",
    "                    boxstyle=\"round,pad=0.2\",\n",
    "                    fc=\"white\",\n",
    "                    ec=\"#555555\",\n",
    "                    alpha=0.9,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    leg = plt.legend(frameon=True, fontsize=10, loc=\"upper right\")\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=250)\n",
    "    plt.close()\n",
    "    print(f\"Saved fancy plot: {filename}\")\n",
    "\n",
    "\n",
    "# UMN-style colors for combined plots\n",
    "UMN_MAROON = \"#7A0019\"\n",
    "UMN_GOLD = \"#FFCC33\"\n",
    "BTJ_GRAY = \"#555555\"\n",
    "\n",
    "\n",
    "def plot_gap_and_overall_combined(\n",
    "    per_season_acc: pd.DataFrame,\n",
    "    filename: str = \"q2_gap_overall_combined.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a figure with two subplots:\n",
    "\n",
    "      Left:  smoothed accuracy gaps vs Rank by season\n",
    "             (Percent − Rank, BT+Judge − Rank).\n",
    "\n",
    "      Right: overall mean accuracy by method (Rank, Percent, BT+Judge)\n",
    "             with standard-deviation error bars.\n",
    "\n",
    "    Uses UMN maroon/gold/gray color scheme.\n",
    "    \"\"\"\n",
    "    if per_season_acc.empty:\n",
    "        print(\"No per-season accuracy data to plot.\")\n",
    "        return\n",
    "\n",
    "    seasons = per_season_acc[\"season\"].values\n",
    "    acc_rank = per_season_acc[\"rank_accuracy\"].values\n",
    "    acc_pct = per_season_acc[\"pct_accuracy\"].values\n",
    "    acc_btj = per_season_acc[\"btj_accuracy\"].values\n",
    "\n",
    "    # ---- gaps vs Rank ----\n",
    "    gap_pct = acc_pct - acc_rank\n",
    "    gap_btj = acc_btj - acc_rank\n",
    "\n",
    "    x_s_pct, gap_pct_s = _smooth_xy(\n",
    "        seasons, gap_pct, n_points=300, clip_min=-0.5, clip_max=0.5\n",
    "    )\n",
    "    x_s_btj, gap_btj_s = _smooth_xy(\n",
    "        seasons, gap_btj, n_points=300, clip_min=-0.5, clip_max=0.5\n",
    "    )\n",
    "\n",
    "    # ---- overall stats for right subplot ----\n",
    "    means = {\n",
    "        \"Rank Sum\": float(np.nanmean(acc_rank)),\n",
    "        \"Percent Sum\": float(np.nanmean(acc_pct)),\n",
    "        \"BT+Judge\": float(np.nanmean(acc_btj)),\n",
    "    }\n",
    "    stds = {\n",
    "        \"Rank Sum\": float(np.nanstd(acc_rank)),\n",
    "        \"Percent Sum\": float(np.nanstd(acc_pct)),\n",
    "        \"BT+Judge\": float(np.nanstd(acc_btj)),\n",
    "    }\n",
    "    method_order = [\"Rank Sum\", \"Percent Sum\", \"BT+Judge\"]\n",
    "    colors = {\n",
    "        \"Rank Sum\": UMN_MAROON,\n",
    "        \"Percent Sum\": UMN_GOLD,\n",
    "        \"BT+Judge\": BTJ_GRAY,\n",
    "    }\n",
    "\n",
    "    fig, (ax_left, ax_right) = plt.subplots(\n",
    "        1, 2, figsize=(13, 5), gridspec_kw={\"width_ratios\": [3, 1]}\n",
    "    )\n",
    "\n",
    "    # ---------------- LEFT: smooth gaps ----------------\n",
    "    ax = ax_left\n",
    "    ax.set_facecolor(\"#f8f9fa\")\n",
    "    ax.grid(\n",
    "        True, which=\"both\", axis=\"both\", alpha=0.2, linestyle=\"--\", linewidth=0.7\n",
    "    )\n",
    "\n",
    "    ax.axhline(0, color=\"#555555\", linestyle=\"--\", linewidth=1.0, alpha=0.7)\n",
    "\n",
    "    # Percent − Rank (gold)\n",
    "    ax.fill_between(\n",
    "        x_s_pct,\n",
    "        0,\n",
    "        gap_pct_s,\n",
    "        where=(gap_pct_s >= 0),\n",
    "        color=UMN_GOLD,\n",
    "        alpha=0.35,\n",
    "    )\n",
    "    ax.plot(\n",
    "        x_s_pct,\n",
    "        gap_pct_s,\n",
    "        color=UMN_GOLD,\n",
    "        linewidth=2.2,\n",
    "        label=\"Percent − Rank\",\n",
    "    )\n",
    "\n",
    "    # BT+Judge − Rank (gray)\n",
    "    ax.fill_between(\n",
    "        x_s_btj,\n",
    "        0,\n",
    "        gap_btj_s,\n",
    "        where=(gap_btj_s >= 0),\n",
    "        color=BTJ_GRAY,\n",
    "        alpha=0.25,\n",
    "    )\n",
    "    ax.plot(\n",
    "        x_s_btj,\n",
    "        gap_btj_s,\n",
    "        color=BTJ_GRAY,\n",
    "        linewidth=2.0,\n",
    "        label=\"BT+Judge − Rank\",\n",
    "    )\n",
    "\n",
    "    # Actual season points\n",
    "    ax.scatter(\n",
    "        seasons,\n",
    "        gap_pct,\n",
    "        s=35,\n",
    "        color=UMN_GOLD,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.9,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        seasons,\n",
    "        gap_btj,\n",
    "        s=35,\n",
    "        color=BTJ_GRAY,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.9,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Season\", fontsize=11)\n",
    "    ax.set_ylabel(\"Accuracy Difference\\n(Method − Rank)\", fontsize=11)\n",
    "    ax.set_xticks(np.arange(seasons.min(), seasons.max() + 1, 2))\n",
    "    ax.set_ylim(-0.5, 0.45)\n",
    "\n",
    "    ax.text(\n",
    "        seasons.min() + 0.3,\n",
    "        0.42,\n",
    "        \"↑ Above 0: method outperforms Rank\",\n",
    "        fontsize=9,\n",
    "        color=\"#444444\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    ax.text(\n",
    "        seasons.min() + 0.3,\n",
    "        -0.47,\n",
    "        \"↓ Below 0: Rank outperforms method\",\n",
    "        fontsize=9,\n",
    "        color=\"#444444\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "    leg = ax.legend(frameon=True, fontsize=9, loc=\"upper right\")\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    ax.set_title(\"Gap vs Rank by season\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    # ---------------- RIGHT: overall bar chart ----------------\n",
    "    ax2 = ax_right\n",
    "    ax2.set_facecolor(\"#f8f9fa\")\n",
    "    ax2.grid(\n",
    "        True, axis=\"x\", alpha=0.2, linestyle=\"--\", linewidth=0.7\n",
    "    )\n",
    "\n",
    "    y_pos = np.arange(len(method_order))\n",
    "    mean_vals = [means[m] for m in method_order]\n",
    "    err_vals = [stds[m] for m in method_order]\n",
    "    bar_cols = [colors[m] for m in method_order]\n",
    "\n",
    "    ax2.barh(\n",
    "        y_pos,\n",
    "        mean_vals,\n",
    "        xerr=err_vals,\n",
    "        color=bar_cols,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(method_order, fontsize=10)\n",
    "    ax2.invert_yaxis()  # Rank on top\n",
    "\n",
    "    ax2.set_xlim(0.4, 1.0)\n",
    "    ax2.set_xlabel(\"Mean accuracy over seasons\", fontsize=11)\n",
    "    ax2.set_title(\n",
    "        \"Overall performance by method\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    for i, v in enumerate(mean_vals):\n",
    "        ax2.text(\n",
    "            v + 0.01,\n",
    "            i,\n",
    "            f\"{v:.2f}\",\n",
    "            va=\"center\",\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            color=\"#333333\",\n",
    "        )\n",
    "\n",
    "    fig.suptitle(\n",
    "        \"Comparison of Voting Rules vs Observed Eliminations\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        y=1.03,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(filename, dpi=260, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved combined gap+overall plot: {filename}\")\n",
    "\n",
    "\n",
    "def make_extraordinary_table(placement_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a compact summary table for extraordinary / controversial contestants.\n",
    "    \"\"\"\n",
    "    extraordinary = [\n",
    "        (\"Jerry Rice\", 2),\n",
    "        (\"Billy Ray Cyrus\", 4),\n",
    "        (\"Bristol Palin\", 11),\n",
    "        (\"Bristol Palin\", 15),\n",
    "        (\"Bobby Bones\", 27),\n",
    "    ]\n",
    "\n",
    "    rows: list[dict] = []\n",
    "\n",
    "    for name, season in extraordinary:\n",
    "        sub = placement_df[\n",
    "            (placement_df[\"celebrity_name\"] == name)\n",
    "            & (placement_df[\"season\"] == season)\n",
    "        ]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        r = sub.iloc[0]\n",
    "        rows.append(\n",
    "            {\n",
    "                \"Season\": season,\n",
    "                \"Contestant\": name,\n",
    "                \"Observed Place\": r[\"place_obs\"],\n",
    "                \"Rank Rule Place\": r[\"place_rank\"],\n",
    "                \"Percent Rule Place\": r[\"place_pct\"],\n",
    "                \"BT+Judge Place\": r[\"place_btj\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    table = pd.DataFrame(rows)\n",
    "\n",
    "    print(\"\\n=== Extraordinary Contestants Analysis ===\")\n",
    "    if not table.empty:\n",
    "        print(table.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No extraordinary contestants found in placement_df.\")\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def plot_extraordinary_placements(\n",
    "    placement_df: pd.DataFrame,\n",
    "    filename: str = \"q2_extraordinary_placements.png\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot placement comparison for extraordinary contestants under\n",
    "    observed, Rank, Percent, and BT+J rules.\n",
    "\n",
    "    Dot-plot style: x = contestant, y = placement (1 = winner).\n",
    "    \"\"\"\n",
    "    cases = [\n",
    "        (\"Jerry Rice\", 2),\n",
    "        (\"Billy Ray Cyrus\", 4),\n",
    "        (\"Bristol Palin\", 11),\n",
    "        (\"Bristol Palin\", 15),\n",
    "        (\"Bobby Bones\", 27),\n",
    "    ]\n",
    "\n",
    "    records: list[dict] = []\n",
    "    for name, season in cases:\n",
    "        sub = placement_df[\n",
    "            (placement_df[\"celebrity_name\"] == name)\n",
    "            & (placement_df[\"season\"] == season)\n",
    "        ]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        r = sub.iloc[0]\n",
    "        label = f\"S{season}: {name}\"\n",
    "        records.append(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"place_obs\": r[\"place_obs\"],\n",
    "                \"place_rank\": r[\"place_rank\"],\n",
    "                \"place_pct\": r[\"place_pct\"],\n",
    "                \"place_btj\": r[\"place_btj\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not records:\n",
    "        print(\"No extraordinary contestants found in placement_df.\")\n",
    "        return\n",
    "\n",
    "    tbl = pd.DataFrame(records)\n",
    "    x_labels = tbl[\"label\"].tolist()\n",
    "    x = np.arange(len(x_labels))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"#f8f9fa\")\n",
    "    ax.grid(\n",
    "        True, axis=\"y\", alpha=0.2, linestyle=\"--\", linewidth=0.7\n",
    "    )\n",
    "\n",
    "    width = 0.15\n",
    "    offsets = {\n",
    "        \"Observed\": -1.5 * width,\n",
    "        \"Rank\": -0.5 * width,\n",
    "        \"Percent\": 0.5 * width,\n",
    "        \"BT+Judge\": 1.5 * width,\n",
    "    }\n",
    "\n",
    "    ax.scatter(\n",
    "        x + offsets[\"Observed\"],\n",
    "        tbl[\"place_obs\"],\n",
    "        s=70,\n",
    "        marker=\"o\",\n",
    "        color=\"black\",\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        label=\"Observed\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        x + offsets[\"Rank\"],\n",
    "        tbl[\"place_rank\"],\n",
    "        s=70,\n",
    "        marker=\"o\",\n",
    "        color=UMN_MAROON,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        label=\"Rank Sum\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        x + offsets[\"Percent\"],\n",
    "        tbl[\"place_pct\"],\n",
    "        s=70,\n",
    "        marker=\"s\",\n",
    "        color=UMN_GOLD,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        label=\"Percent Sum\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        x + offsets[\"BT+Judge\"],\n",
    "        tbl[\"place_btj\"],\n",
    "        s=80,\n",
    "        marker=\"D\",\n",
    "        color=BTJ_GRAY,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.0,\n",
    "        label=\"Bottom-Two + Judge\",\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=20, ha=\"right\")\n",
    "\n",
    "    ax.set_ylabel(\"Placement (1 = winner, larger = earlier elimination)\")\n",
    "    ax.set_title(\n",
    "        \"Placement of Extraordinary Contestants\\n\"\n",
    "        \"Observed vs Rank, Percent, and Bottom-Two + Judge\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "        pad=10,\n",
    "    )\n",
    "\n",
    "    ymax = max(\n",
    "        tbl[\"place_obs\"].max(),\n",
    "        tbl[\"place_rank\"].max(),\n",
    "        tbl[\"place_pct\"].max(),\n",
    "        tbl[\"place_btj\"].max(),\n",
    "    )\n",
    "    ax.set_ylim(0.5, ymax + 0.5)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    leg = ax.legend(frameon=True, fontsize=10, loc=\"upper right\")\n",
    "    leg.get_frame().set_facecolor(\"white\")\n",
    "    leg.get_frame().set_edgecolor(\"#cccccc\")\n",
    "    leg.get_frame().set_alpha(0.9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=260)\n",
    "    plt.close()\n",
    "    print(f\"Saved extraordinary placement plot: {filename}\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 7. Script entry point: tie everything together\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # Load fan model output\n",
    "    df = pd.read_csv(\"fan_shares_estimated.csv\")\n",
    "\n",
    "    # 1) Simulate methods\n",
    "    week_results = simulate_all_methods(df)\n",
    "\n",
    "    # 2) Global and per-season summaries\n",
    "    summary_global, per_season_disagree = summarize_week_results(\n",
    "        week_results\n",
    "    )\n",
    "    print(\"=== Global summary (Rank vs Percent) ===\")\n",
    "    for k, v in summary_global.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    print(\"\\n=== Per-season disagreement summary (head) ===\")\n",
    "    print(per_season_disagree.head().to_string(index=False))\n",
    "\n",
    "    # 3) Per-season accuracy for all 3 methods + summary plot\n",
    "    per_season_acc = compute_per_season_accuracy(week_results)\n",
    "    plot_gap_and_overall_combined(\n",
    "        per_season_acc, filename=\"q2_gap_overall_combined.png\"\n",
    "    )\n",
    "\n",
    "    # 4) Placements for every contestant & placement plots\n",
    "    placement_df = compute_placements_per_season(week_results, df)\n",
    "    plot_extraordinary_placements(\n",
    "        placement_df, filename=\"q2_extraordinary_placements.png\"\n",
    "    )\n",
    "\n",
    "    # 5) Extraordinary contestants table (for writeup / appendix)\n",
    "    make_extraordinary_table(placement_df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
