{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69694b6d",
   "metadata": {},
   "source": [
    "## Decomposed Fan Utility Model for η and F\n",
    "\n",
    "This script refines the latent fan-utility index \\( \\eta_{i,s,t} \\) from Question 1 by decomposing it into:\n",
    "\n",
    "\\[\n",
    "\\eta_{i,s,t} \\approx \\underbrace{\\eta^{\\text{lin}}_{i,s,t}}_{\\text{linear backbone}}\n",
    "\\;+\\;\n",
    "\\underbrace{\\eta^{\\text{ML}}_{i,s,t}}_{\\text{nonlinear attribute correction}}.\n",
    "\\]\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "- `2026_MCM_Problem_C_Data.csv` (COMAP raw wide-format data)\n",
    "- `fan_shares_estimated.csv` (Question 1 output), with at least:\n",
    "  - `season`, `week`, `celebrity_name`\n",
    "  - `fan_share_hat` (reconstructed fan share)\n",
    "  - `judge_std` (standardized judge score)\n",
    "\n",
    "**Modeling steps**\n",
    "\n",
    "1. **Construct panel with attributes.**\n",
    "   - Merge `fan_shares_estimated.csv` with static contestant attributes from the raw COMAP file:\n",
    "     - `celebrity_age_during_season`\n",
    "     - `celebrity_industry`\n",
    "     - `ballroom_partner`\n",
    "     - `celebrity_homecountry/region`.\n",
    "   - Define the baseline log-utility:\n",
    "     \\[\n",
    "     \\eta_{\\text{hat}} = \\log(\\text{fan\\_share\\_hat} + 10^{-12}).\n",
    "     \\]\n",
    "\n",
    "2. **Linear backbone for \\(\\eta\\).**\n",
    "   - Fit a linear regression:\n",
    "     \\[\n",
    "     \\eta_{\\text{hat}} \\sim \\text{judge\\_std} + \\text{week}\n",
    "     + \\text{age} + \\text{industry} + \\text{pro} + \\text{homecountry},\n",
    "     \\]\n",
    "     where numeric features are standardized and categorical features are one-hot encoded.\n",
    "   - Store residuals \\(\\eta_{\\text{resid}} = \\eta_{\\text{hat}} - \\eta^{\\text{lin}}\\).\n",
    "\n",
    "3. **GBDT for residual structure.**\n",
    "   - Fit a `GradientBoostingRegressor` on \\(\\eta_{\\text{resid}}\\) using *only static attributes*:\n",
    "     - age, industry, pro partner, home country.\n",
    "   - This learns a flexible nonlinear correction \\(\\eta^{\\text{ML}}\\) capturing interaction effects and attribute patterns not explained by the linear model.\n",
    "\n",
    "4. **Reconstructed decomposed utility and fan shares.**\n",
    "   - For every panel row, compute:\n",
    "     - `eta_lin` — linear prediction from the backbone.\n",
    "     - `eta_ml` — nonlinear correction from GBDT.\n",
    "     - `eta_decomp = eta_lin + eta_ml`.\n",
    "   - Convert `eta_decomp` to implied fan shares via a **within-week softmax**:\n",
    "     \\[\n",
    "     F^{\\text{decomp}}_{i,s,t}\n",
    "       = \\frac{\\exp(\\eta^{\\text{decomp}}_{i,s,t})}\n",
    "              {\\sum_{j \\in \\mathcal{A}_{s,t}} \\exp(\\eta^{\\text{decomp}}_{j,s,t})},\n",
    "     \\]\n",
    "     saved as column `F_decomp`.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "- `panel_with_eta_decomp.csv`:\n",
    "  - original panel plus:\n",
    "    - `eta_hat`, `eta_resid`\n",
    "    - `eta_lin`, `eta_ml`, `eta_decomp`\n",
    "    - `F_decomp`.\n",
    "- Serialized models for reuse and diagnostics:\n",
    "  - `lin_eta_model.joblib` and `lin_feature_names.joblib`\n",
    "  - `gbdt_eta_model.joblib` and `gbdt_feature_names.joblib`.\n",
    "\n",
    "These objects are used later in the report to:\n",
    "- interpret linear coefficients (e.g., effect of age or industry on \\(\\eta\\)),\n",
    "- inspect GBDT feature importances for nonlinear attribute effects,\n",
    "- and plug `F_decomp` into downstream simulations of alternative voting rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f6a4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "eta_decomposition.py\n",
    "\n",
    "Refine the latent utility index eta_hat for DWTS fan support by:\n",
    "  - Fitting a linear backbone model in judge_std, week, and static attributes.\n",
    "  - Fitting a Gradient Boosting model on the residuals using static attributes.\n",
    "  - Reconstructing a decomposed utility:\n",
    "        eta_decomp = eta_lin + eta_ml\n",
    "    and the implied fan shares via softmax within each (season, week).\n",
    "\n",
    "Inputs:\n",
    "  - 2026_MCM_Problem_C_Data.csv       (raw COMAP-style wide data)\n",
    "  - fan_shares_estimated.csv          (Question 1 output)\n",
    "\n",
    "Outputs:\n",
    "  - panel_with_eta_decomp.csv         (long panel with eta/F decomposition)\n",
    "  - lin_eta_model.joblib              (linear backbone model)\n",
    "  - lin_feature_names.joblib          (names of encoded linear features)\n",
    "  - gbdt_eta_model.joblib             (GBDT residual model)\n",
    "  - gbdt_feature_names.joblib         (names of encoded GBDT features)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. File paths (change these if needed)\n",
    "# ============================================================\n",
    "\n",
    "RAW_DATA_PATH = \"2026_MCM_Problem_C_Data.csv\"\n",
    "FAN_EST_PATH = \"fan_shares_estimated.csv\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Helper: numerically stable softmax\n",
    "# ============================================================\n",
    "\n",
    "def softmax_stable(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Numerically stable softmax for a 1D numpy array.\n",
    "    Used within each (season, week) group to convert eta -> F.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    x_shifted = x - x.max()\n",
    "    ex = np.exp(x_shifted)\n",
    "    return ex / ex.sum()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Linear backbone for eta_hat\n",
    "# ============================================================\n",
    "\n",
    "def fit_eta_linear(df_panel: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fit a linear regression for eta_hat as a function of:\n",
    "      - judge_std, week, age (numeric)\n",
    "      - industry, pro partner, homecountry (categorical)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_panel : DataFrame\n",
    "        Must contain columns:\n",
    "          - 'eta_hat'\n",
    "          - 'judge_std'\n",
    "          - 'week'\n",
    "          - 'celebrity_age_during_season'\n",
    "          - 'celebrity_industry'\n",
    "          - 'ballroom_partner'\n",
    "          - 'celebrity_homecountry/region'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lin_model : Pipeline\n",
    "        Preprocessing + LinearRegression model for eta_hat.\n",
    "    df_out : DataFrame\n",
    "        Copy of df_panel with an extra column 'eta_resid' (residuals).\n",
    "    feature_names : np.ndarray\n",
    "        Names of the encoded features used in the linear model.\n",
    "    \"\"\"\n",
    "    df = df_panel.copy()\n",
    "    y = df[\"eta_hat\"].values\n",
    "\n",
    "    # Numeric features in the linear part\n",
    "    num_features = [\"judge_std\", \"week\", \"celebrity_age_during_season\"]\n",
    "\n",
    "    # Categorical features – one-hot encoded\n",
    "    home_country_col = \"celebrity_homecountry/region\"\n",
    "    cat_features = [\n",
    "        \"celebrity_industry\",\n",
    "        \"ballroom_partner\",\n",
    "        home_country_col,\n",
    "    ]\n",
    "\n",
    "    X = df[num_features + cat_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_features),\n",
    "            (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lin_model = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"lin\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    lin_model.fit(X, y)\n",
    "    y_pred_lin = lin_model.predict(X)\n",
    "    residuals = y - y_pred_lin\n",
    "\n",
    "    print(\"Linear model R^2 on eta_hat: {:.3f}\".format(r2_score(y, y_pred_lin)))\n",
    "\n",
    "    df[\"eta_resid\"] = residuals\n",
    "\n",
    "    # Recover feature names for interpretation\n",
    "    ohe = lin_model.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "    cat_encoded_names = ohe.get_feature_names_out(cat_features)\n",
    "    feature_names = np.concatenate([num_features, cat_encoded_names])\n",
    "\n",
    "    # Inspect largest coefficients (optional, but nice to see in logs)\n",
    "    coefs = lin_model.named_steps[\"lin\"].coef_\n",
    "    coef_df = (\n",
    "        pd.DataFrame({\"feature\": feature_names, \"coef_eta\": coefs})\n",
    "        .sort_values(\"coef_eta\", key=lambda s: s.abs(), ascending=False)\n",
    "    )\n",
    "\n",
    "    print(\"\\nTop 20 linear coefficients for eta_hat:\")\n",
    "    print(coef_df.head(20))\n",
    "\n",
    "    return lin_model, df, feature_names\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. GBDT model on eta residuals\n",
    "# ============================================================\n",
    "\n",
    "def fit_eta_residual_gbdt(df_with_resid: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fit GradientBoostingRegressor on residuals of eta_hat\n",
    "    using static attributes only (no judge_std or week).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_with_resid : DataFrame\n",
    "        Must contain 'eta_resid' and static attribute columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gbdt_model : Pipeline\n",
    "        Preprocessing + GradientBoostingRegressor trained on residuals.\n",
    "    feat_names : np.ndarray\n",
    "        Encoded feature names used by the GBDT.\n",
    "    \"\"\"\n",
    "    df = df_with_resid.copy()\n",
    "    r = df[\"eta_resid\"].values\n",
    "\n",
    "    # Only static attributes here\n",
    "    num_features = [\"celebrity_age_during_season\"]\n",
    "    home_country_col = \"celebrity_homecountry/region\"\n",
    "    cat_features = [\n",
    "        \"celebrity_industry\",\n",
    "        \"ballroom_partner\",\n",
    "        home_country_col,\n",
    "    ]\n",
    "\n",
    "    X = df[num_features + cat_features]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(), num_features),\n",
    "            (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), cat_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    gbdt_model = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"gbr\", GradientBoostingRegressor(\n",
    "            random_state=0,\n",
    "            n_estimators=300,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    gbdt_model.fit(X, r)\n",
    "    r_pred = gbdt_model.predict(X)\n",
    "\n",
    "    print(\"GBDT R^2 on eta residuals: {:.3f}\".format(r2_score(r, r_pred)))\n",
    "\n",
    "    ohe = gbdt_model.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "    cat_names = ohe.get_feature_names_out(cat_features)\n",
    "    feat_names = np.concatenate([num_features, cat_names])\n",
    "\n",
    "    importances = gbdt_model.named_steps[\"gbr\"].feature_importances_\n",
    "    order = np.argsort(importances)[::-1]\n",
    "\n",
    "    print(\"\\nTop 20 GBDT feature importances for residual eta:\")\n",
    "    for idx in order[:20]:\n",
    "        print(f\"{feat_names[idx]:40s} {importances[idx]:.4f}\")\n",
    "\n",
    "    return gbdt_model, feat_names\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Build eta_lin, eta_ml, eta_decomp, F_decomp\n",
    "# ============================================================\n",
    "\n",
    "def add_eta_and_F_decomp(df_panel: pd.DataFrame,\n",
    "                         lin_model: Pipeline,\n",
    "                         gbdt_model: Pipeline) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute decomposed eta and implied fan shares from the fitted models.\n",
    "\n",
    "    Adds the following columns:\n",
    "      - 'eta_lin'    : linear backbone prediction\n",
    "      - 'eta_ml'     : nonlinear ML correction (GBDT)\n",
    "      - 'eta_decomp' : sum of the two\n",
    "      - 'F_decomp'   : softmax over eta_decomp within each (season, week)\n",
    "    \"\"\"\n",
    "    df = df_panel.copy()\n",
    "\n",
    "    # Linear part uses judge_std, week, age + categorical attrs\n",
    "    num_features_all = [\"judge_std\", \"week\", \"celebrity_age_during_season\"]\n",
    "    home_country_col = \"celebrity_homecountry/region\"\n",
    "    cat_features_all = [\n",
    "        \"celebrity_industry\",\n",
    "        \"ballroom_partner\",\n",
    "        home_country_col,\n",
    "    ]\n",
    "    X_all = df[num_features_all + cat_features_all]\n",
    "    eta_lin = lin_model.predict(X_all)\n",
    "\n",
    "    # GBDT part uses static attributes only\n",
    "    num_features_static = [\"celebrity_age_during_season\"]\n",
    "    cat_features_static = [\n",
    "        \"celebrity_industry\",\n",
    "        \"ballroom_partner\",\n",
    "        home_country_col,\n",
    "    ]\n",
    "    X_static = df[num_features_static + cat_features_static]\n",
    "    eta_ml = gbdt_model.predict(X_static)\n",
    "\n",
    "    df[\"eta_lin\"] = eta_lin\n",
    "    df[\"eta_ml\"] = eta_ml\n",
    "    df[\"eta_decomp\"] = df[\"eta_lin\"] + df[\"eta_ml\"]\n",
    "\n",
    "    # Softmax per (season, week) to get decomposed fan shares\n",
    "    df[\"F_decomp\"] = (\n",
    "        df.groupby([\"season\", \"week\"])[\"eta_decomp\"]\n",
    "          .transform(softmax_stable)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. Main script\n",
    "# ============================================================\n",
    "\n",
    "def main() -> None:\n",
    "    # 1) Load raw COMAP data and fan-share estimates\n",
    "    df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "    df_fan = pd.read_csv(FAN_EST_PATH)\n",
    "\n",
    "    # Static attributes (one row per contestant-season)\n",
    "    attrs_cols = [\n",
    "        \"season\",\n",
    "        \"celebrity_name\",\n",
    "        \"celebrity_age_during_season\",\n",
    "        \"celebrity_industry\",\n",
    "        \"ballroom_partner\",\n",
    "        \"celebrity_homecountry/region\",\n",
    "    ]\n",
    "    df_attrs = df_raw[attrs_cols].drop_duplicates()\n",
    "\n",
    "    # Merge attributes into fan panel\n",
    "    df_panel = df_fan.merge(\n",
    "        df_attrs,\n",
    "        on=[\"season\", \"celebrity_name\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Define eta_hat as log fan share (Question 1 latent utility proxy)\n",
    "    df_panel[\"eta_hat\"] = np.log(df_panel[\"fan_share_hat\"] + 1e-12)\n",
    "\n",
    "    print(\"df_panel shape:\", df_panel.shape)\n",
    "    print(\"Columns:\", df_panel.columns.tolist())\n",
    "\n",
    "    # 2) Fit linear backbone\n",
    "    lin_eta, df_with_resid, lin_feat_names = fit_eta_linear(df_panel)\n",
    "\n",
    "    # 3) Fit residual GBDT on static attributes\n",
    "    gbdt_eta, gbdt_feat_names = fit_eta_residual_gbdt(df_with_resid)\n",
    "\n",
    "    # 4) Build decomposed eta and fan shares\n",
    "    df_eta_full = add_eta_and_F_decomp(df_with_resid, lin_eta, gbdt_eta)\n",
    "\n",
    "    print(\"\\nFinished. df_eta_full columns now include:\")\n",
    "    print([c for c in df_eta_full.columns if c.startswith(\"eta_\") or c.startswith(\"F_\")])\n",
    "\n",
    "    # 5) Save panel and models\n",
    "    df_eta_full.to_csv(\"panel_with_eta_decomp.csv\", index=False)\n",
    "    dump(lin_eta, \"lin_eta_model.joblib\")\n",
    "    dump(lin_feat_names, \"lin_feature_names.joblib\")\n",
    "    dump(gbdt_eta, \"gbdt_eta_model.joblib\")\n",
    "    dump(gbdt_feat_names, \"gbdt_feature_names.joblib\")\n",
    "\n",
    "    print(\"Saved panel_with_eta_decomp.csv and model joblib files.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2550f04",
   "metadata": {},
   "source": [
    "## Figure 6: Baseline Fan Popularity by Industry and Professional Partner\n",
    "\n",
    "This script visualizes how **attribute-driven fan utility** (the nonlinear ML component \\(\\eta_{\\text{ml}}\\) from the decomposed model) varies across contestant industries and professional partners.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "- `panel_with_eta_decomp.csv`  \n",
    "  Long panel produced by the eta–decomposition script, containing at least:\n",
    "  - `season`, `celebrity_name`\n",
    "  - `eta_ml` – the ML residual utility component\n",
    "  - (optionally) `celebrity_industry`, `ballroom_partner`\n",
    "\n",
    "- `2026_MCM_Problem_C_Data.csv`  \n",
    "  Used only if `celebrity_industry` or `ballroom_partner` are missing from the panel; the script merges those attributes back in.\n",
    "\n",
    "### Processing Steps\n",
    "\n",
    "1. **Ensure attributes are present.**  \n",
    "   If `celebrity_industry` or `ballroom_partner` are missing in `df_eta`, they are merged from the raw COMAP data using `(season, celebrity_name)`.\n",
    "\n",
    "2. **Collapse to contestant–season level.**  \n",
    "   For each `(season, celebrity_name)`, the script averages `eta_ml` over weeks:\n",
    "   \\[\n",
    "   \\eta_{\\text{ml, mean}} = \\text{mean}_t\\; \\eta_{\\text{ml}, i,s,t}\n",
    "   \\]\n",
    "   The resulting dataframe `df_c` has one row per contestant–season with:\n",
    "   - `celebrity_industry`\n",
    "   - `ballroom_partner`\n",
    "   - `eta_ml_mean`\n",
    "\n",
    "3. **Industry grouping (Fig. 6a).**\n",
    "   - Count how many contestants appear in each `celebrity_industry`.\n",
    "   - Keep the **top 7 industries**, group all others into `\"Other\"`.\n",
    "   - For each industry (including `\"Other\"`), collect the distribution of `eta_ml_mean`.\n",
    "   - Plot a **horizontal boxplot**:\n",
    "     - x-axis: `eta_ml_mean` (attribute-driven utility)\n",
    "     - y-axis: industry categories\n",
    "     - Title: *“Fig. 6(a). Baseline Fan Popularity by Industry”*\n",
    "\n",
    "4. **Professional partner grouping (Fig. 6b).**\n",
    "   - Count how many contestant–seasons each `ballroom_partner` appears in.\n",
    "   - Keep pros with at least 6 contestants, then take the **top 10** by frequency.\n",
    "   - For each such partner, collect the distribution of `eta_ml_mean`.\n",
    "   - Plot another horizontal boxplot:\n",
    "     - x-axis: `eta_ml_mean`\n",
    "     - y-axis: professional partners\n",
    "     - Title: *“Fig. 6(b). Baseline Fan Popularity by Professional Partner”*\n",
    "\n",
    "5. **Styling and output.**\n",
    "   - Uses **UMN-style colors**:\n",
    "     - Maroon outlines (`#7A0019`)\n",
    "     - Light gold fills (`#FFE6A6`)\n",
    "   - Removes top/right spines and adds light x-grid lines.\n",
    "   - Saves the combined figure as:\n",
    "     - `Fig6_industry_pro.png`\n",
    "     - `Fig6_industry_pro.pdf`\n",
    "\n",
    "### Interpretation Use\n",
    "\n",
    "- Each box summarizes the distribution of **baseline fan popularity** \\(\\eta_{\\text{ml}}\\) for a given group.\n",
    "- Higher medians and upper quartiles indicate industries or professional partners associated with systematically stronger fan support **beyond** what judge scores and week effects explain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fab04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- paths (change if needed) ----------\n",
    "RAW_DATA_PATH   = \"2026_MCM_Problem_C_Data.csv\"\n",
    "PANEL_PATH      = \"panel_with_eta_decomp.csv\"\n",
    "\n",
    "# ---------- colors ----------\n",
    "MAROON     = \"#7A0019\"\n",
    "LIGHT_GOLD = \"#FFE6A6\"\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 11,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"figure.facecolor\": \"white\"\n",
    "})\n",
    "\n",
    "# =========================================================\n",
    "# 1. Load panel & make sure attributes exist\n",
    "# =========================================================\n",
    "df_eta = pd.read_csv(PANEL_PATH)\n",
    "\n",
    "needed_cols = [\"celebrity_industry\", \"ballroom_partner\"]\n",
    "missing = [c for c in needed_cols if c not in df_eta.columns]\n",
    "\n",
    "if missing:\n",
    "    df_raw = pd.read_csv(RAW_DATA_PATH)\n",
    "    attrs_cols = [\"season\", \"celebrity_name\"] + needed_cols\n",
    "    df_attrs = df_raw[attrs_cols].drop_duplicates()\n",
    "    df_eta = df_eta.merge(\n",
    "        df_attrs,\n",
    "        on=[\"season\", \"celebrity_name\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "# Collapse to contestant–season level\n",
    "df_c = (\n",
    "    df_eta\n",
    "    .groupby(\n",
    "        [\"season\", \"celebrity_name\",\n",
    "         \"celebrity_industry\", \"ballroom_partner\"],\n",
    "        as_index=False\n",
    "    )[\"eta_ml\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"eta_ml\": \"eta_ml_mean\"})\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Build Figure 6\n",
    "# =========================================================\n",
    "fig6, axes = plt.subplots(1, 2, figsize=(11, 4.8), sharey=True)\n",
    "\n",
    "# ---------- Fig. 6(a): Industry ----------\n",
    "ind_counts = df_c[\"celebrity_industry\"].value_counts()\n",
    "top_inds = ind_counts.head(7).index  # top 7 industries\n",
    "df_c[\"industry_simplified\"] = np.where(\n",
    "    df_c[\"celebrity_industry\"].isin(top_inds),\n",
    "    df_c[\"celebrity_industry\"],\n",
    "    \"Other\"\n",
    ")\n",
    "\n",
    "ind_order = (\n",
    "    df_c.groupby(\"industry_simplified\")[\"eta_ml_mean\"]\n",
    "        .median()\n",
    "        .sort_values()\n",
    "        .index\n",
    ")\n",
    "\n",
    "data_ind = [\n",
    "    df_c.loc[df_c[\"industry_simplified\"] == ind, \"eta_ml_mean\"]\n",
    "    for ind in ind_order\n",
    "]\n",
    "\n",
    "bp_ind = axes[0].boxplot(\n",
    "    data_ind,\n",
    "    vert=False,\n",
    "    patch_artist=True\n",
    ")\n",
    "\n",
    "for patch in bp_ind[\"boxes\"]:\n",
    "    patch.set(facecolor=LIGHT_GOLD, edgecolor=MAROON, alpha=0.9)\n",
    "for median in bp_ind[\"medians\"]:\n",
    "    median.set(color=MAROON, linewidth=2)\n",
    "for whisker in bp_ind[\"whiskers\"]:\n",
    "    whisker.set(color=MAROON, linewidth=0.8)\n",
    "for cap in bp_ind[\"caps\"]:\n",
    "    cap.set(color=MAROON, linewidth=0.8)\n",
    "for flier in bp_ind[\"fliers\"]:\n",
    "    flier.set(marker=\"o\", markersize=3, alpha=0.4,\n",
    "              markerfacecolor=MAROON, markeredgecolor=\"none\")\n",
    "\n",
    "axes[0].set_yticks(range(1, len(ind_order) + 1))\n",
    "axes[0].set_yticklabels(ind_order, fontsize=9)\n",
    "axes[0].set_xlabel(\"Attribute-driven utility (η_ml)\")\n",
    "axes[0].set_title(\"Fig. 6(a). Baseline Fan Popularity by Industry\")\n",
    "axes[0].grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    axes[0].spines[spine].set_visible(False)\n",
    "\n",
    "# ---------- Fig. 6(b): Professional partner ----------\n",
    "pro_counts = df_c[\"ballroom_partner\"].value_counts()\n",
    "top_pros = pro_counts[pro_counts >= 6].head(10).index  # top 10 frequent pros\n",
    "df_pro = df_c[df_c[\"ballroom_partner\"].isin(top_pros)]\n",
    "\n",
    "pro_order = (\n",
    "    df_pro.groupby(\"ballroom_partner\")[\"eta_ml_mean\"]\n",
    "          .median()\n",
    "          .sort_values()\n",
    "          .index\n",
    ")\n",
    "\n",
    "data_pro = [\n",
    "    df_pro.loc[df_pro[\"ballroom_partner\"] == pro, \"eta_ml_mean\"]\n",
    "    for pro in pro_order\n",
    "]\n",
    "\n",
    "bp_pro = axes[1].boxplot(\n",
    "    data_pro,\n",
    "    vert=False,\n",
    "    patch_artist=True\n",
    ")\n",
    "\n",
    "for patch in bp_pro[\"boxes\"]:\n",
    "    patch.set(facecolor=LIGHT_GOLD, edgecolor=MAROON, alpha=0.9)\n",
    "for median in bp_pro[\"medians\"]:\n",
    "    median.set(color=MAROON, linewidth=2)\n",
    "for whisker in bp_pro[\"whiskers\"]:\n",
    "    whisker.set(color=MAROON, linewidth=0.8)\n",
    "for cap in bp_pro[\"caps\"]:\n",
    "    cap.set(color=MAROON, linewidth=0.8)\n",
    "for flier in bp_pro[\"fliers\"]:\n",
    "    flier.set(marker=\"o\", markersize=3, alpha=0.4,\n",
    "              markerfacecolor=MAROON, markeredgecolor=\"none\")\n",
    "\n",
    "axes[1].set_yticks(range(1, len(pro_order) + 1))\n",
    "axes[1].set_yticklabels(pro_order, fontsize=9)\n",
    "axes[1].set_xlabel(\"Attribute-driven utility (η_ml)\")\n",
    "axes[1].set_title(\"Fig. 6(b). Baseline Fan Popularity by Professional Partner\")\n",
    "axes[1].grid(axis=\"x\", linestyle=\"--\", alpha=0.3)\n",
    "for spine in [\"top\", \"right\"]:\n",
    "    axes[1].spines[spine].set_visible(False)\n",
    "\n",
    "fig6.tight_layout()\n",
    "\n",
    "# ---------- Show and save ----------\n",
    "plt.show()\n",
    "\n",
    "fig6.savefig(\"Fig6_industry_pro.png\", dpi=300, bbox_inches=\"tight\")\n",
    "fig6.savefig(\"Fig6_industry_pro.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(\"Saved Figure 6 as Fig6_industry_pro.png and Fig6_industry_pro.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ece9d",
   "metadata": {},
   "source": [
    "More Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85282df1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1. Average nonlinear fan effect by home country\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Average eta_ml by home country\n",
    "country_effect = (\n",
    "    df_eta_full\n",
    "    .groupby(\"celebrity_homecountry/region\")[\"eta_ml\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "# Optionally filter to countries with enough data\n",
    "min_n = 20\n",
    "country_counts = df_eta_full[\"celebrity_homecountry/region\"].value_counts()\n",
    "valid_countries = country_counts[country_counts >= min_n].index\n",
    "country_effect = country_effect.loc[valid_countries]\n",
    "\n",
    "# Take extremes (e.g., 8 lowest and 8 highest) to keep the plot readable\n",
    "# country_effect is already sorted\n",
    "# country_effect: Series indexed by country, values = mean eta_ml\n",
    "\n",
    "k = min(8, len(country_effect))  # at most 8, but never more than we have\n",
    "\n",
    "head_part = country_effect.head(k)\n",
    "tail_part = country_effect.tail(k)\n",
    "\n",
    "effect_subset = pd.concat([head_part, tail_part])\n",
    "\n",
    "# Remove any duplicates if the head and tail overlap (e.g., total < 2k)\n",
    "effect_subset = effect_subset[~effect_subset.index.duplicated(keep=\"first\")]\n",
    "\n",
    "\n",
    "# Make labels a bit shorter (optional)\n",
    "effect_subset.index = effect_subset.index.str.replace(\"United States\", \"USA\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. GBDT feature importances for country dummies\n",
    "# ------------------------------------------------\n",
    "\n",
    "importances = gbdt_eta.named_steps[\"gbr\"].feature_importances_\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": gbdt_feat_names,\n",
    "    \"importance\": importances,\n",
    "})\n",
    "\n",
    "country_imp = (\n",
    "    imp_df[imp_df[\"feature\"].str.startswith(\"celebrity_homecountry/region_\")]\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "# Top 10 most important country dummies\n",
    "country_imp_top = country_imp.head(10).copy()\n",
    "# Clean up feature names for display\n",
    "country_imp_top[\"label\"] = (\n",
    "    country_imp_top[\"feature\"]\n",
    "    .str.replace(\"celebrity_homecountry/region_\", \"\", regex=False)\n",
    "    .str.replace(\"United States\", \"USA\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Plot: two subplots side by side\n",
    "# ------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# --- Left: average η_ml effect by country ---\n",
    "ax = axes[0]\n",
    "effect_subset.plot(kind=\"barh\", ax=ax)\n",
    "ax.axvline(0, color=\"black\", linewidth=1)\n",
    "ax.set_xlabel(\"Average nonlinear fan utility effect (η_ml)\")\n",
    "ax.set_ylabel(\"Home country / region\")\n",
    "ax.set_title(\"Home Country Effect on Fan Support (η_ml)\")\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# Make labels a bit smaller if many categories\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontsize(9)\n",
    "\n",
    "# --- Right: GBDT importance for country dummies ---\n",
    "ax2 = axes[1]\n",
    "ax2.barh(country_imp_top[\"label\"], country_imp_top[\"importance\"])\n",
    "ax2.invert_yaxis()  # highest importance at top\n",
    "ax2.set_xlabel(\"GBDT feature importance\")\n",
    "ax2.set_title(\"Most Influential Home Country Indicators\")\n",
    "ax2.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "for label in ax2.get_yticklabels():\n",
    "    label.set_fontsize(9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd210a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Partial dependence-style plot using eta_ml\n",
    "age = df_eta_full[\"celebrity_age_during_season\"]\n",
    "eta_ml = df_eta_full[\"eta_ml\"]\n",
    "\n",
    "# Bin ages\n",
    "bins = np.linspace(age.min(), age.max(), 12)\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "eta_by_age = []\n",
    "for lo, hi in zip(bins[:-1], bins[1:]):\n",
    "    mask = (age >= lo) & (age < hi)\n",
    "    eta_by_age.append(eta_ml[mask].mean())\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(bin_centers, eta_by_age, marker=\"o\")\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Celebrity age during season\")\n",
    "plt.ylabel(\"Average nonlinear fan utility (η_ml)\")\n",
    "plt.title(\"Nonlinear Effect of Age on Fan Support\")\n",
    "plt.grid(alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
