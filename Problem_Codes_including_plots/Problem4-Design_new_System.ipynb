{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17c9216",
   "metadata": {},
   "source": [
    "## Hybrid DWTS Elimination System (Simulation Script)\n",
    "\n",
    "This script simulates a **proposed DWTS elimination system** that blends judges’ scores, fan support, and momentum, while enforcing fairness shields for both judges and fans.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "- `panel_with_eta_decomp.csv`, containing at least:\n",
    "  - `season`, `week`, `contestant_id`\n",
    "  - `judge_total` – raw weekly judge total\n",
    "  - `eta_decomp` – decomposed latent utility for fans\n",
    "  - `F_decomp` – fan share implied by `eta_decomp`\n",
    "  - `eliminated` – 1 if historically eliminated this week, else 0\n",
    "\n",
    "### Design Hyperparameters\n",
    "\n",
    "- **Fan temperatures**\n",
    "  - `GAMMA_SCORE` – controls how sharply fan utilities translate into fan shares for scoring.\n",
    "  - `GAMMA_ELIM` – same for bottom-two fan decision.\n",
    "- **Momentum**\n",
    "  - `K_MOMENTUM` – lookback window (in weeks) for fan momentum.\n",
    "- **Judge weights**\n",
    "  - `ALPHA_J_START`, `ALPHA_J_END` – judge weight increases over the season.\n",
    "  - `ALPHA_M` – fixed weight on momentum.\n",
    "  - Implied fan weight:  \n",
    "    \\[\n",
    "    \\alpha_F = 1 - \\alpha_J - \\alpha_M\n",
    "    \\]\n",
    "- **Fairness / shield rules**\n",
    "  - `THETA_F` – fan-protection threshold (strong favorites).\n",
    "  - `TOP_JUDGE_K`, `BOT_FAN_K`, `BOT_JUDGE_K` – how many top/bottom positions define shield sets.\n",
    "\n",
    "### Main Components\n",
    "\n",
    "1. **Helper functions**\n",
    "   - `softmax(x)` – numerically stable softmax over a 1D array.\n",
    "   - `add_normalized_judges(...)` – adds `J_norm` = judge_total normalized within each `(season, week)`.\n",
    "   - `add_momentum_from_F(...)` – computes fan momentum:\n",
    "     \\[\n",
    "     M_{it} = \\max\\bigl(0, F_{it} - \\text{avg of last K weeks}\\bigr)\n",
    "     \\]\n",
    "   - `compute_week_progress(...)` – computes season progress\n",
    "     \\[\n",
    "     \\tau_{st} = \\frac{\\text{week} - 1}{T_s - 1}\n",
    "     \\]\n",
    "     used to interpolate judge weight from early to late season.\n",
    "   - `dense_rank_descending(values)` – dense rank (1 = largest), used for judge/fan ranks.\n",
    "\n",
    "2. **Preprocessing**\n",
    "   - Load `panel_with_eta_decomp.csv`.\n",
    "   - Check required columns.\n",
    "   - Add:\n",
    "     - `J_norm` – within-week normalized judge scores.\n",
    "     - `momentum` – fan momentum from `F_decomp`.\n",
    "     - `week_progress` – season progress scalar.\n",
    "   - Sort by `season`, `week`, `contestant_id` for stable processing.\n",
    "\n",
    "3. **Weekly simulation loop**\n",
    "\n",
    "   For each `(season, week)` where **exactly one historical elimination** occurs:\n",
    "\n",
    "   1. **Fan shares**\n",
    "      - Compute `F_score = softmax(GAMMA_SCORE * eta_decomp)` for scoring.\n",
    "      - Compute `F_elim  = softmax(GAMMA_ELIM * eta_decomp)` for final bottom-two decision.\n",
    "\n",
    "   2. **Dynamic weights**\n",
    "      - Interpolate judge weight:\n",
    "        \\[\n",
    "        \\alpha_J(t) = \\alpha_{J,\\text{start}} + (\\alpha_{J,\\text{end}} - \\alpha_{J,\\text{start}})\\,\\tau_{st}\n",
    "        \\]\n",
    "      - Use fixed `ALPHA_M`, then set:\n",
    "        \\[\n",
    "        \\alpha_F(t) = 1 - \\alpha_J(t) - \\alpha_M.\n",
    "        \\]\n",
    "\n",
    "   3. **Risk score**\n",
    "      - Combined “at-risk” score:\n",
    "        \\[\n",
    "        S_i = \\alpha_J J_i + \\alpha_F F^{\\text{score}}_i + \\alpha_M M_i.\n",
    "        \\]\n",
    "\n",
    "   4. **Shields / protection**\n",
    "      - Compute dense ranks:\n",
    "        - `rJ` – judge rank (1 = best judge).\n",
    "        - `rF` – fan rank (1 = highest fan share).\n",
    "      - **Judge shield**:\n",
    "        - Protect contestants who are:\n",
    "          - In the top `TOP_JUDGE_K` by judges, and\n",
    "          - Not in the bottom `BOT_FAN_K` by fans.\n",
    "      - **Fan shield**:\n",
    "        - Protect contestants with `F_elim ≥ THETA_F` (strong favorites), **unless** they are in the bottom `BOT_JUDGE_K` by judges.\n",
    "      - Union of both shields = full protected set.\n",
    "      - Eligible set = contestants not protected.  \n",
    "        If everyone is protected, fall back to all contestants being eligible.\n",
    "\n",
    "   5. **Bottom-two and final elimination**\n",
    "      - Among eligible contestants, pick **bottom two** by `S` (lowest scores).\n",
    "      - Within this bottom-two, eliminate the contestant with **lower** fan share (`F_elim`).\n",
    "\n",
    "   6. **Evaluation vs history**\n",
    "      - `hit` – whether predicted elimination matches the historical elimination.\n",
    "      - `judge_conflict` – whether the eliminated contestant is **different** from the worst judge scorer (i.e., this shows judge–fan tension).\n",
    "      - Track fan variance `var(F_score)` as an inequality measure.\n",
    "\n",
    "   7. **Logging for plots**\n",
    "      - `weight_log` – store `alpha_J`, `alpha_F`, `alpha_M` by `(season, week)` for weight-evolution plots.\n",
    "      - `example_week_df` – capture the first week where the system conflicts with judges, storing per-contestant decomposition:\n",
    "        - `J_part`, `F_part`, `M_part`, `S_total`\n",
    "        - predicted vs true elimination flags.\n",
    "\n",
    "4. **Summary metrics**\n",
    "\n",
    "After all weeks:\n",
    "\n",
    "- `hit_rate` – fraction of weeks where the system exactly matches the historical elimination.\n",
    "- `conflict_rate` – fraction of weeks where the system’s elimination differs from the worst judge.\n",
    "- `mean_fan_var` – average within-week variance of `F_score`, reflecting fan inequality.\n",
    "\n",
    "The script prints:\n",
    "\n",
    "- Global performance summary.\n",
    "- A sample of `results_df` (per-week outcomes).\n",
    "- A preview of `weights_df` (for plotting weight trajectories).\n",
    "- A preview of `example_week_df` (for visualization of one “interesting” conflict week, if found).\n",
    "\n",
    "### Outputs (in-memory)\n",
    "\n",
    "- `results_df` – per-week results (hit, conflict, weights, predicted/true eliminated IDs).\n",
    "- `weights_df` – per-week judge/fan/momentum weights.\n",
    "- `example_week_df` – one week with a judge–fan conflict, ready for a stacked-bar decomposition figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5287af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proposed DWTS elimination system:\n",
    "\n",
    "- Score-based combination of judges, fans, and momentum\n",
    "- Week-dependent judge/fan weights\n",
    "- Judge- and fan-shield fairness rules\n",
    "- Bottom-two selection by score\n",
    "- Final elimination decided by fan share within bottom-two\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 0. Hyperparameters (design choices)\n",
    "# ============================================================\n",
    "\n",
    "PANEL_PATH = \"panel_with_eta_decomp.csv\"\n",
    "\n",
    "# Fan temperature for scoring and final elimination\n",
    "GAMMA_SCORE = 0.7\n",
    "GAMMA_ELIM = 1.0\n",
    "\n",
    "# Momentum parameters\n",
    "K_MOMENTUM = 3  # lookback window in weeks\n",
    "\n",
    "# Phase-dependent judge weights\n",
    "ALPHA_J_START = 0.3\n",
    "ALPHA_J_END = 0.6\n",
    "\n",
    "# Fixed momentum weight\n",
    "ALPHA_M = 0.2\n",
    "\n",
    "# Fan protection threshold (strong favorites)\n",
    "THETA_F = 0.30\n",
    "\n",
    "# Top/bottom cutoffs for shields\n",
    "TOP_JUDGE_K = 2\n",
    "BOT_FAN_K = 2\n",
    "BOT_JUDGE_K = 2\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Helpers\n",
    "# ============================================================\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Numerically stable softmax over 1D numpy array.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.max(x)\n",
    "    ex = np.exp(x - m)\n",
    "    return ex / ex.sum()\n",
    "\n",
    "\n",
    "def add_normalized_judges(df,\n",
    "                          group_cols=(\"season\", \"week\"),\n",
    "                          judge_col=\"judge_total\",\n",
    "                          out_col=\"J_norm\"):\n",
    "    df = df.copy()\n",
    "    df[out_col] = df.groupby(list(group_cols))[judge_col].transform(\n",
    "        lambda s: s / s.sum() if s.sum() != 0 else 0.0\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_momentum_from_F(df,\n",
    "                        season_col=\"season\",\n",
    "                        contestant_col=\"contestant_id\",\n",
    "                        week_col=\"week\",\n",
    "                        F_col=\"F_decomp\",\n",
    "                        out_col=\"momentum\",\n",
    "                        K=3):\n",
    "    \"\"\"\n",
    "    M_it = max(0, F_it - avg of last K weeks for that contestant in that season)\n",
    "    using historical fan share estimate F_decomp.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[out_col] = 0.0\n",
    "    df = df.sort_values(by=[season_col, contestant_col, week_col])\n",
    "\n",
    "    groups = df.groupby([season_col, contestant_col], sort=False)\n",
    "    momentum_values = []\n",
    "\n",
    "    for (s, cid), sub in groups:\n",
    "        sub = sub.sort_values(by=week_col)\n",
    "        F_vals = sub[F_col].values\n",
    "        m_vals = np.zeros_like(F_vals, dtype=float)\n",
    "\n",
    "        for idx in range(1, len(F_vals)):\n",
    "            k = min(idx, K)\n",
    "            prev_mean = F_vals[idx - k:idx].mean()\n",
    "            m_vals[idx] = max(0.0, F_vals[idx] - prev_mean)\n",
    "\n",
    "        momentum_values.append(pd.Series(m_vals, index=sub.index))\n",
    "\n",
    "    momentum_series = pd.concat(momentum_values).sort_index()\n",
    "    df.loc[momentum_series.index, out_col] = momentum_series.values\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_week_progress(df, season_col=\"season\", week_col=\"week\"):\n",
    "    \"\"\"\n",
    "    tau_{st} = (week - 1) / (T_s - 1)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    max_week = df.groupby(season_col)[week_col].max().to_dict()\n",
    "\n",
    "    def tau(row):\n",
    "        T_s = max_week[row[season_col]]\n",
    "        if T_s <= 1:\n",
    "            return 0.0\n",
    "        return (row[week_col] - 1) / (T_s - 1)\n",
    "\n",
    "    df[\"week_progress\"] = df.apply(tau, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def dense_rank_descending(values):\n",
    "    \"\"\"\n",
    "    Dense rank, 1 = largest, n = smallest.\n",
    "    values: 1D numpy array\n",
    "    \"\"\"\n",
    "    order = np.argsort(-values)  # descending\n",
    "    ranks = np.empty_like(order, dtype=int)\n",
    "    # assign ranks\n",
    "    current_rank = 1\n",
    "    for i, idx in enumerate(order):\n",
    "        if i > 0 and values[idx] != values[order[i - 1]]:\n",
    "            current_rank = i + 1\n",
    "        ranks[idx] = current_rank\n",
    "    return ranks\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Load panel and preprocess\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(PANEL_PATH)\n",
    "\n",
    "print(\"Loaded panel_with_eta_decomp.csv\")\n",
    "print(df.head())\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Rows:\", len(df))\n",
    "\n",
    "required_cols = [\"season\", \"week\", \"contestant_id\",\n",
    "                 \"judge_total\", \"eta_decomp\", \"F_decomp\", \"eliminated\"]\n",
    "for c in required_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Column '{c}' missing from panel_with_eta_decomp.csv\")\n",
    "\n",
    "# Normalize judges\n",
    "df = add_normalized_judges(df,\n",
    "                           group_cols=(\"season\", \"week\"),\n",
    "                           judge_col=\"judge_total\",\n",
    "                           out_col=\"J_norm\")\n",
    "\n",
    "# Momentum from F_decomp\n",
    "df = add_momentum_from_F(df,\n",
    "                         season_col=\"season\",\n",
    "                         contestant_col=\"contestant_id\",\n",
    "                         week_col=\"week\",\n",
    "                         F_col=\"F_decomp\",\n",
    "                         out_col=\"momentum\",\n",
    "                         K=K_MOMENTUM)\n",
    "\n",
    "# Week progress tau_{st}\n",
    "df = compute_week_progress(df,\n",
    "                           season_col=\"season\",\n",
    "                           week_col=\"week\")\n",
    "\n",
    "print(\"\\nBasic checks:\")\n",
    "print(\"Unique seasons:\", df[\"season\"].unique())\n",
    "print(\"Weeks per season (head):\")\n",
    "print(df.groupby(\"season\")[\"week\"].max().head())\n",
    "print(\"Total eliminated=1 rows:\", df[\"eliminated\"].sum())\n",
    "\n",
    "# Sort for consistent processing\n",
    "df = df.sort_values(by=[\"season\", \"week\", \"contestant_id\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Simulate proposed system week by week\n",
    "# ============================================================\n",
    "\n",
    "results = []  # per-week outcomes\n",
    "\n",
    "# ==== NEW: logs for plots ====\n",
    "weight_log = []        # for panel (b): alpha_J/F/M over weeks\n",
    "fan_var_list = []      # you already had this, keep it\n",
    "example_week_df = None # for panel (d): one representative week\n",
    "\n",
    "unique_weeks = df[[\"season\", \"week\"]].drop_duplicates().sort_values([\"season\", \"week\"])\n",
    "\n",
    "hits = 0\n",
    "total_weeks = 0\n",
    "conflicts_with_judges = 0\n",
    "\n",
    "for _, wk in unique_weeks.iterrows():\n",
    "    s = wk[\"season\"]\n",
    "    t = wk[\"week\"]\n",
    "\n",
    "    sub = df[(df[\"season\"] == s) & (df[\"week\"] == t)].copy()\n",
    "    sub = sub.sort_values(\"contestant_id\")\n",
    "\n",
    "    # Only simulate weeks with exactly one historical elimination\n",
    "    if sub[\"eliminated\"].sum() != 1:\n",
    "        continue\n",
    "\n",
    "    total_weeks += 1\n",
    "\n",
    "    # Extract arrays\n",
    "    J = sub[\"J_norm\"].values.astype(float)\n",
    "    eta = sub[\"eta_decomp\"].values.astype(float)\n",
    "    M = sub[\"momentum\"].values.astype(float)\n",
    "    elim_true = sub[\"eliminated\"].values.astype(int)\n",
    "    tau = sub[\"week_progress\"].iloc[0]  # all same within week\n",
    "\n",
    "    n = len(sub)\n",
    "\n",
    "    # Fan shares for scoring and elimination\n",
    "    F_score = softmax(GAMMA_SCORE * eta)\n",
    "    F_elim = softmax(GAMMA_ELIM * eta)\n",
    "\n",
    "    # Week-dependent weights\n",
    "    alpha_J_t = ALPHA_J_START + (ALPHA_J_END - ALPHA_J_START) * tau\n",
    "    alpha_M_t = ALPHA_M\n",
    "    alpha_F_t = 1.0 - alpha_J_t - alpha_M_t\n",
    "\n",
    "    # ==== NEW: log weights for this week ====\n",
    "    weight_log.append({\n",
    "        \"season\": s,\n",
    "        \"week\": t,\n",
    "        \"alpha_J\": alpha_J_t,\n",
    "        \"alpha_F\": alpha_F_t,\n",
    "        \"alpha_M\": alpha_M_t\n",
    "    })\n",
    "\n",
    "    # Risk score\n",
    "    S = alpha_J_t * J + alpha_F_t * F_score + alpha_M_t * M\n",
    "\n",
    "    # Ranks and protection sets\n",
    "    rJ = dense_rank_descending(J)           # 1=best judge\n",
    "    rF = dense_rank_descending(F_elim)      # 1=most fans\n",
    "\n",
    "    # Indices (0..n-1)\n",
    "    idx = np.arange(n)\n",
    "\n",
    "    # Judge-shield: top-J, not bottom-fan\n",
    "    # top-J = rank <= TOP_JUDGE_K\n",
    "    # bottom-fan = among worst BOT_FAN_K by fans\n",
    "    bottom_fan_threshold = n - BOT_FAN_K + 1  # e.g., if n=6, BOT_FAN_K=2 -> ranks >=5\n",
    "    topJ_mask = rJ <= TOP_JUDGE_K\n",
    "    botF_mask = rF >= bottom_fan_threshold\n",
    "    P_judge = idx[topJ_mask & (~botF_mask)]\n",
    "\n",
    "    # Fan-shield: strong favorites, not bottom-J\n",
    "    bottom_judge_threshold = n - BOT_JUDGE_K + 1\n",
    "    favF_mask = F_elim >= THETA_F\n",
    "    botJ_mask = rJ >= bottom_judge_threshold\n",
    "    P_fan = idx[favF_mask & (~botJ_mask)]\n",
    "\n",
    "    protected = set(P_judge.tolist()) | set(P_fan.tolist())\n",
    "\n",
    "    # Eligible for elimination\n",
    "    eligible_mask = np.array([i not in protected for i in idx])\n",
    "    eligible_idx = idx[eligible_mask]\n",
    "\n",
    "    # Fallback: if somehow everyone is protected, relax shields\n",
    "    if len(eligible_idx) == 0:\n",
    "        eligible_idx = idx.copy()\n",
    "\n",
    "    # Bottom-two by score S among eligible\n",
    "    # (if only one eligible, that one plus best non-protected as backup)\n",
    "    S_eligible = S[eligible_idx]\n",
    "    order_elig = np.argsort(S_eligible)  # ascending = most at-risk\n",
    "    if len(order_elig) >= 2:\n",
    "        btm_indices = eligible_idx[order_elig[:2]]\n",
    "    else:\n",
    "        # only one eligible; pair with next-worst overall by S\n",
    "        worst_idx = eligible_idx[order_elig[0]]\n",
    "        other_candidates = idx[idx != worst_idx]\n",
    "        second_idx = other_candidates[np.argsort(S[other_candidates])[0]]\n",
    "        btm_indices = np.array([worst_idx, second_idx])\n",
    "\n",
    "    # Final elimination decided by fans within bottom-two\n",
    "    F_btm = F_elim[btm_indices]\n",
    "    # Eliminate the one with LOWER fan share\n",
    "    elim_btm_order = np.argsort(F_btm)     # ascending fan share => more likely eliminated\n",
    "    elim_pred_idx = btm_indices[elim_btm_order[0]]\n",
    "\n",
    "    # Compare with historical elimination\n",
    "    true_elim_idx = idx[elim_true == 1][0]\n",
    "    hit = int(elim_pred_idx == true_elim_idx)\n",
    "    hits += hit\n",
    "\n",
    "    # Conflict with judges: compare to worst judge (lowest J)\n",
    "    worst_judge_idx = idx[np.argmin(J)]\n",
    "    conflict = int(elim_pred_idx != worst_judge_idx)\n",
    "    conflicts_with_judges += conflict\n",
    "\n",
    "    # Fan variance (based on scoring fan shares)\n",
    "    fan_var_list.append(np.var(F_score))\n",
    "\n",
    "    # Save weekly result (for table / debugging)\n",
    "    results.append({\n",
    "        \"season\": s,\n",
    "        \"week\": t,\n",
    "        \"alpha_J_t\": alpha_J_t,\n",
    "        \"alpha_F_t\": alpha_F_t,\n",
    "        \"alpha_M_t\": alpha_M_t,\n",
    "        \"pred_elim_contestant_id\": sub[\"contestant_id\"].iloc[elim_pred_idx],\n",
    "        \"true_elim_contestant_id\": sub[\"contestant_id\"].iloc[true_elim_idx],\n",
    "        \"hit\": hit,\n",
    "        \"judge_conflict\": conflict\n",
    "    })\n",
    "\n",
    "    # ==== NEW: capture one representative week for decomposition plot ====\n",
    "    # Take the first week where there is a judge–fan conflict (to make the plot interesting)\n",
    "    if example_week_df is None and conflict == 1:\n",
    "        example_week_df = pd.DataFrame({\n",
    "            \"season\": s,\n",
    "            \"week\": t,\n",
    "            \"contestant_id\": sub[\"contestant_id\"].values,\n",
    "            \"J_part\": alpha_J_t * J,\n",
    "            \"F_part\": alpha_F_t * F_score,\n",
    "            \"M_part\": alpha_M_t * M,\n",
    "            \"S_total\": S,\n",
    "            \"pred_eliminated\": (idx == elim_pred_idx).astype(int),\n",
    "            \"true_eliminated\": elim_true\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# 4. Summary metrics\n",
    "# ============================================================\n",
    "\n",
    "hit_rate = hits / total_weeks if total_weeks > 0 else 0.0\n",
    "conflict_rate = conflicts_with_judges / total_weeks if total_weeks > 0 else 0.0\n",
    "mean_fan_var = float(np.mean(fan_var_list)) if fan_var_list else 0.0\n",
    "\n",
    "print(\"\\n=== Proposed system performance ===\")\n",
    "print(f\"Weeks evaluated: {total_weeks}\")\n",
    "print(f\"Hit rate (match historical elimination)      : {hit_rate:.3f}\")\n",
    "print(f\"Conflict rate (≠ worst judge)                : {conflict_rate:.3f}\")\n",
    "print(f\"Mean fan variance (inequality measure)       : {mean_fan_var:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSample of weekly results:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# ==== NEW: build helper objects for plotting ====\n",
    "weights_df = pd.DataFrame(weight_log)\n",
    "cher_metrics = {\n",
    "    \"hit_rate\": hit_rate,\n",
    "    \"conflict_rate\": conflict_rate,\n",
    "    \"mean_fan_var\": mean_fan_var\n",
    "}\n",
    "\n",
    "print(\"\\nWeights_df head (for panel (b)):\")\n",
    "print(weights_df.head())\n",
    "\n",
    "if example_week_df is not None:\n",
    "    print(\"\\nExample week for decomposition plot (panel (d)):\")\n",
    "    print(example_week_df.head())\n",
    "else:\n",
    "    print(\"\\nWarning: no week with judge–fan conflict was found for example_week_df.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf7f29",
   "metadata": {},
   "source": [
    "## Figure: Performance of the Proposed CHER Elimination System\n",
    "\n",
    "This figure summarizes the behavior and performance of the **CHER (Composite Hybrid Elimination Rule)** system by combining global performance metrics, dynamic weighting behavior, system-level comparisons, and a concrete weekly example.\n",
    "\n",
    "The figure consists of four panels:\n",
    "\n",
    "---\n",
    "\n",
    "### (a) Accuracy–Conflict Trade-off\n",
    "\n",
    "Each point represents one parameter configuration evaluated in the grid search.\n",
    "\n",
    "- **x-axis:** Conflict rate — how often the system’s elimination disagrees with the lowest judge score.\n",
    "- **y-axis:** Hit rate — how often the predicted elimination matches the historical outcome.\n",
    "- **Color:** Mean fan variance — a measure of inequality in fan support within a week.\n",
    "\n",
    "The red star highlights the **proposed CHER configuration**, illustrating where it lies in the trade-off space.  \n",
    "This panel shows that CHER achieves a competitive hit rate while keeping judge–fan conflicts and fan inequality at moderate levels.\n",
    "\n",
    "---\n",
    "\n",
    "### (b) Dynamic Aggregation Weights\n",
    "\n",
    "This panel shows the **average weekly aggregation weights** used by CHER:\n",
    "\n",
    "- \\(\\alpha_J\\): judge weight  \n",
    "- \\(\\alpha_F\\): fan weight  \n",
    "- \\(\\alpha_M\\): momentum weight  \n",
    "\n",
    "Weights are averaged across seasons to avoid noisy season-specific trajectories.  \n",
    "The plot illustrates the intended design:\n",
    "- Judge influence increases over time,\n",
    "- Fan influence decreases accordingly,\n",
    "- Momentum remains fixed.\n",
    "\n",
    "---\n",
    "\n",
    "### (c) System-Level Comparison\n",
    "\n",
    "This bar chart compares three systems:\n",
    "\n",
    "- **Fan-only**\n",
    "- **Judge-only**\n",
    "- **CHER**\n",
    "\n",
    "For each system, three metrics are shown:\n",
    "- Hit rate\n",
    "- Conflict rate\n",
    "- Fan variance\n",
    "\n",
    "CHER balances all three objectives, avoiding the extreme conflict of fan-only rules and the low responsiveness of judge-only rules, while maintaining lower fan inequality.\n",
    "\n",
    "---\n",
    "\n",
    "### (d) One-Week Score Decomposition\n",
    "\n",
    "This panel provides a transparent, **contestant-level breakdown** for a representative week:\n",
    "\n",
    "- Stacked bars show contributions from:\n",
    "  - Judges\n",
    "  - Fans\n",
    "  - Momentum\n",
    "- The dashed vertical line marks the **historically eliminated contestant**.\n",
    "\n",
    "This visualization demonstrates how the final elimination emerges from the combined scoring components and highlights cases where fan and judge signals compete.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Interpretation\n",
    "\n",
    "Together, the four panels show that CHER:\n",
    "- Achieves strong agreement with historical eliminations,\n",
    "- Smoothly transitions influence from fans to judges over the season,\n",
    "- Maintains fairness through bounded fan inequality,\n",
    "- Remains interpretable at both the system and individual-week level.\n",
    "\n",
    "This makes CHER a transparent and robust alternative to fixed-rule elimination systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775f118",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")  # nicer default look\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 9))\n",
    "plt.subplots_adjust(hspace=0.35, wspace=0.3)\n",
    "\n",
    "# =========================================================\n",
    "# (a) Accuracy–Conflict Trade-off\n",
    "# =========================================================\n",
    "ax = axs[0, 0]\n",
    "\n",
    "sc = ax.scatter(\n",
    "    grid_results[\"conflict_rate\"],\n",
    "    grid_results[\"hit_rate\"],\n",
    "    c=grid_results[\"mean_fan_var\"],\n",
    "    cmap=\"viridis\",\n",
    "    s=18,\n",
    "    alpha=0.85,\n",
    "    linewidths=0\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    cher_metrics[\"conflict_rate\"],\n",
    "    cher_metrics[\"hit_rate\"],\n",
    "    color=\"red\",\n",
    "    s=120,\n",
    "    marker=\"*\",\n",
    "    label=\"Proposed CHER\",\n",
    "    zorder=5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Conflict rate\", fontsize=11)\n",
    "ax.set_ylabel(\"Hit rate\", fontsize=11)\n",
    "ax.set_title(\"(a) Accuracy–Conflict Trade-off\", fontsize=13)\n",
    "ax.legend(frameon=True, fontsize=10)\n",
    "cbar = plt.colorbar(sc, ax=ax)\n",
    "cbar.set_label(\"Mean fan variance\", fontsize=11)\n",
    "\n",
    "# optional: tighten limits a bit\n",
    "ax.set_xlim(grid_results[\"conflict_rate\"].min() - 0.02,\n",
    "            grid_results[\"conflict_rate\"].max() + 0.02)\n",
    "ax.set_ylim(grid_results[\"hit_rate\"].min() - 0.01,\n",
    "            grid_results[\"hit_rate\"].max() + 0.01)\n",
    "\n",
    "# =========================================================\n",
    "# (b) Dynamic aggregation weights (clean version)\n",
    "#    -> use mean across seasons instead of many zig-zag lines\n",
    "# =========================================================\n",
    "ax = axs[0, 1]\n",
    "\n",
    "weights_mean = (\n",
    "    weights_df\n",
    "    .groupby(\"week\", as_index=False)[[\"alpha_J\", \"alpha_F\", \"alpha_M\"]]\n",
    "    .mean()\n",
    "    .sort_values(\"week\")\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    weights_mean[\"week\"], weights_mean[\"alpha_J\"],\n",
    "    marker=\"o\", label=r\"$\\alpha_J$\"\n",
    ")\n",
    "ax.plot(\n",
    "    weights_mean[\"week\"], weights_mean[\"alpha_F\"],\n",
    "    marker=\"s\", label=r\"$\\alpha_F$\"\n",
    ")\n",
    "ax.plot(\n",
    "    weights_mean[\"week\"], weights_mean[\"alpha_M\"],\n",
    "    marker=\"^\", label=r\"$\\alpha_M$\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Week\", fontsize=11)\n",
    "ax.set_ylabel(\"Weight\", fontsize=11)\n",
    "ax.set_title(\"(b) Dynamic aggregation weights\", fontsize=13)\n",
    "ax.set_xticks(sorted(weights_mean[\"week\"].unique()))\n",
    "ax.set_ylim(0, 0.7)\n",
    "ax.legend(frameon=True, fontsize=10)\n",
    "\n",
    "# =========================================================\n",
    "# (c) System-level comparison\n",
    "# =========================================================\n",
    "ax = axs[1, 0]\n",
    "\n",
    "labels = [\"Fan-only\", \"Judge-only\", \"CHER\"]\n",
    "\n",
    "hit = [\n",
    "    baseline_metrics[\"fan\"][\"hit\"],\n",
    "    baseline_metrics[\"judge\"][\"hit\"],\n",
    "    cher_metrics[\"hit_rate\"],\n",
    "]\n",
    "\n",
    "conflict = [\n",
    "    baseline_metrics[\"fan\"][\"conflict\"],\n",
    "    baseline_metrics[\"judge\"][\"conflict\"],\n",
    "    cher_metrics[\"conflict_rate\"],\n",
    "]\n",
    "\n",
    "fanvar = [\n",
    "    baseline_metrics[\"fan\"][\"fan_var\"],\n",
    "    baseline_metrics[\"judge\"][\"fan_var\"],\n",
    "    cher_metrics[\"mean_fan_var\"],\n",
    "]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "w = 0.25\n",
    "\n",
    "ax.bar(x - w, hit, width=w, label=\"Hit rate\")\n",
    "ax.bar(x, conflict, width=w, label=\"Conflict rate\")\n",
    "ax.bar(x + w, fanvar, width=w, label=\"Fan variance\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Value\", fontsize=11)\n",
    "ax.set_title(\"(c) System-level comparison\", fontsize=13)\n",
    "ax.legend(frameon=True, fontsize=10)\n",
    "ax.set_ylim(0, max(max(hit), max(conflict)) * 1.05)\n",
    "\n",
    "# =========================================================\n",
    "# (d) One-week score decomposition\n",
    "# =========================================================\n",
    "ax = axs[1, 1]\n",
    "\n",
    "contestants = example_week_df[\"contestant_id\"].tolist()\n",
    "J = example_week_df[\"J_part\"].values\n",
    "F = example_week_df[\"F_part\"].values\n",
    "M = example_week_df[\"M_part\"].values\n",
    "\n",
    "x = np.arange(len(contestants))\n",
    "\n",
    "ax.bar(x, J, label=\"Judges\")\n",
    "ax.bar(x, F, bottom=J, label=\"Fans\")\n",
    "ax.bar(x, M, bottom=J + F, label=\"Momentum\")\n",
    "\n",
    "true_elim_idx = np.where(example_week_df[\"true_eliminated\"].values == 1)[0][0]\n",
    "\n",
    "ax.axvline(\n",
    "    true_elim_idx,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Historically eliminated\"\n",
    ")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(contestants)\n",
    "ax.set_xlabel(\"Contestant\", fontsize=11)\n",
    "ax.set_ylabel(\"Aggregate score\", fontsize=11)\n",
    "ax.set_title(\"(d) Weekly score decomposition\", fontsize=13)\n",
    "ax.legend(frameon=True, fontsize=10)\n",
    "\n",
    "# =========================================================\n",
    "# Global tweaks\n",
    "# =========================================================\n",
    "for ax in axs.flat:\n",
    "    ax.tick_params(axis=\"both\", labelsize=10)\n",
    "\n",
    "fig.suptitle(\"Performance of the Proposed CHER Elimination System\",\n",
    "             fontsize=15, y=0.98)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
